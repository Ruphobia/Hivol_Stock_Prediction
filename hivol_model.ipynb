{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "hivol-model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFBeoAveCjLq"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "import rank_measure as rm\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Dropout, Dense, Activation\n",
        "from tensorflow.keras.models import load_model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk_SFTsrCjLs"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "def recall(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : \n",
        "    # round : \n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # target set 0(Negative) or 1(Positive)\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # Prediction result set 0(Negative) or 1(Positive)\n",
        "\n",
        "    # True Positive\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Negative) \n",
        "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
        "\n",
        "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
        "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : \n",
        "    # round :\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) \n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) \n",
        "\n",
        "    # True Positive\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Positive) \n",
        "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
        "\n",
        "    # Precision = (True Positive) / (True Positive + False Positive)\n",
        "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1score(y_target, y_pred):\n",
        "    _recall = recall(y_target, y_pred)\n",
        "    _precision = precision(y_target, y_pred)\n",
        "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
        "    \n",
        "    # return a single tensor value\n",
        "    return _f1score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9iygZ9XDCjLt"
      },
      "source": [
        "with tf.device('/GPU:0'):\n",
        "    train_file = np.genfromtxt(\"hivol-file/hivol-train-all.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e7WoFkaCjLt"
      },
      "source": [
        "with tf.device('/GPU:0'):\n",
        "    test_file = np.genfromtxt(\"hivol-file/hivol-test-all.txt\")\n",
        "    now_file = np.genfromtxt(\"hivol-file/hivol-now-all.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmAyBjXyCjLu",
        "outputId": "7cea4780-5f33-4a89-f417-7191c76eec70"
      },
      "source": [
        "print(now_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.0000000e+00  1.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "   2.0000000e+01  2.0191217e+07]\n",
            " [-1.0000000e+00  1.0000000e+00  1.0000000e+00 ...  0.0000000e+00\n",
            "   2.0000000e+01  2.0191218e+07]\n",
            " [ 0.0000000e+00 -1.0000000e+00  1.0000000e+00 ...  0.0000000e+00\n",
            "   2.0000000e+01  2.0191219e+07]\n",
            " ...\n",
            " [-5.0000000e+00  1.2000000e+01  5.0000000e+00 ...  0.0000000e+00\n",
            "   6.8000000e+02  2.0200414e+07]\n",
            " [ 8.0000000e+00  2.2000000e+01 -1.0000000e+00 ...  0.0000000e+00\n",
            "   6.8000000e+02  2.0200611e+07]\n",
            " [ 6.0000000e+00  9.0000000e+00  8.0000000e+00 ...  0.0000000e+00\n",
            "   7.6000000e+02  2.0200619e+07]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cso_5NLCjLv",
        "outputId": "7680f60e-6bb8-4df8-d44b-6e59e511924e"
      },
      "source": [
        "#only indicator feature ex 12 input feature\n",
        "# cci, rsi, bollinger band, \n",
        "print('file loading complete!)\n",
        "# setting default value\n",
        "batch_size = 200  # batch size\n",
        "epochs = 1000\n",
        "input_size  = 20\n",
        "target_num = 2\n",
        "\n",
        "train_x = []\n",
        "train_y = []\n",
        "test_x = []\n",
        "test_y = []\n",
        "code_arr = []\n",
        "date_arr = []\n",
        "vali_x = []\n",
        "vali_y = []\n",
        "\n",
        "vali_x2 = []\n",
        "vali_y2 = []\n",
        "now_x = []\n",
        "now_y = []\n",
        "vali_code_arr = []\n",
        "vali_date_arr = []\n",
        "scores = []\n",
        "predict_code = []\n",
        "predict_date = []\n",
        "record_result_info = []\n",
        "day = []\n",
        "\n",
        "for line in train_file:\n",
        "    x = line[:input_size] #\n",
        "    y = line[input_size:input_size+target_num]\n",
        "    train_x.append(x)\n",
        "    train_y.append(y)\n",
        "\n",
        "for line in test_file:\n",
        "    x = line[:input_size]\n",
        "    y = line[input_size:input_size+target_num]\n",
        "    code = line[input_size+target_num]\n",
        "    date = line[input_size+target_num+1]\n",
        "    test_x.append(x)\n",
        "    test_y.append(y)\n",
        "    code_arr.append(code)\n",
        "    date_arr.append(date)\n",
        "\n",
        "for line in now_file:\n",
        "    x = line[:input_size]\n",
        "    y = line[input_size:input_size+target_num]\n",
        "    code = line[input_size+target_num]\n",
        "    date = line[input_size+target_num+1]\n",
        "    vali_x.append(x)\n",
        "    vali_y.append(y)\n",
        "    vali_code_arr.append(code)\n",
        "    vali_date_arr.append(date)\n",
        "    \n",
        "train_x = np.array(train_x).reshape(-1, input_size)\n",
        "test_x = np.array(test_x).reshape(-1, input_size)\n",
        "vali_x =  np.array(vali_x).reshape(-1, input_size)\n",
        "\n",
        "train_x = pd.DataFrame(train_x)\n",
        "test_x = pd.DataFrame(test_x)\n",
        "vali_x = pd.DataFrame(vali_x)\n",
        "\n",
        "train_y = pd.DataFrame(train_y)\n",
        "test_y = pd.DataFrame(test_y)\n",
        "vali_y =  pd.DataFrame(vali_y)\n",
        "\n",
        "print('train, test date create sucessfully')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일 로딩 완료\n",
            "train, test 파일 분류 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VSy3-K8CjLv",
        "outputId": "fbe92754-19f9-472b-9e75-7471b8c2d392"
      },
      "source": [
        "print(len(train_x))\n",
        "print(len(test_x))\n",
        "print(len(vali_x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410\n",
            "3391\n",
            "3303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBI6iigbCjLw",
        "outputId": "17adda3a-ee4e-4ad3-a8c5-ce1b10d45115"
      },
      "source": [
        "#vali data is used fundsimulation (펀심용)\n",
        "test_len = int(len(test_x)/2)\n",
        "test_x2= test_x[:test_len]\n",
        "test_y2 = test_y[:test_len]\n",
        "now_x = test_x[test_len:]\n",
        "now_y = test_y[test_len:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        0     1     2    3     4     5     6    7       8       9      10  \\\n",
            "1695  0.0   0.0   1.0  0.0   0.0   0.0   1.0  0.0  0.6917 -0.2538 -0.0263   \n",
            "1696  1.0   0.0   0.0 -1.0   0.0   0.0   1.0  0.0  0.8964  0.2133 -0.0657   \n",
            "1697  3.0   1.0   0.0 -2.0  -1.0   0.0   3.0  1.0  1.1982  0.5699  0.1705   \n",
            "1698  6.0   3.0   1.0 -5.0  -2.0  -1.0   1.0  0.0  2.2160  1.2822  0.4505   \n",
            "1699  6.0   6.0   3.0 -3.0  -5.0  -2.0   6.0  2.0  3.6328  2.1007  1.0594   \n",
            "...   ...   ...   ...  ...   ...   ...   ...  ...     ...     ...     ...   \n",
            "3386 -5.0   7.0  22.0  7.0  -2.0   0.0   0.0  0.0  6.5697  1.5354  0.5370   \n",
            "3387 -1.0  14.0   6.0  1.0 -16.0  -6.0   5.0  2.0  4.2139  2.2371  0.8863   \n",
            "3388 -2.0  -1.0  14.0  2.0   1.0 -16.0   0.0  3.0  3.3824  1.9737  0.7075   \n",
            "3389  7.0  22.0   5.0 -2.0   0.0  -5.0  16.0  0.0  5.6253  2.4396  0.7239   \n",
            "3390 -1.0  14.0   6.0  1.0 -16.0  -6.0   5.0  2.0  4.2139  2.2371  0.8863   \n",
            "\n",
            "           11       12       13       14       15       16        17       18  \\\n",
            "1695   0.5556   0.9788  -0.7341 -20.0944   0.0573  -6.0373 -104.4950 -97.5917   \n",
            "1696   0.9661   2.0627   0.6462   9.3378   1.4648   0.0968   -0.7445  10.4342   \n",
            "1697   3.5427   5.2136   4.2274  36.3980  24.0917  10.5625   51.2776  63.7063   \n",
            "1698   7.6235  10.0824   9.9059  28.0696  30.2596  18.0011   61.0310  70.0601   \n",
            "1699  10.0662  13.8300  14.5695  46.7748  35.3535  21.0424   59.9796  74.6846   \n",
            "...       ...      ...      ...      ...      ...      ...       ...      ...   \n",
            "3386  10.2737  14.9895  13.7474   8.4612  14.7157  13.7239  -14.4377  35.3106   \n",
            "3387   9.5308  14.7947  15.6305  15.4555  14.3225  14.4921  -26.7856  35.2912   \n",
            "3388   3.6802  10.5882  12.5943   5.4045   5.0823   5.0351 -251.0049 -78.5376   \n",
            "3389  20.3600  20.4800  18.5000  67.2933  63.9880  58.7057   70.7550  84.5979   \n",
            "3390   9.5308  14.7947  15.6305  15.4555  14.3225  14.4921  -26.7856  35.2912   \n",
            "\n",
            "            19  \n",
            "1695 -150.1762  \n",
            "1696  -11.8489  \n",
            "1697   61.5329  \n",
            "1698   73.0111  \n",
            "1699   81.3160  \n",
            "...        ...  \n",
            "3386   65.1039  \n",
            "3387   66.0983  \n",
            "3388    6.5086  \n",
            "3389   91.5949  \n",
            "3390   66.0983  \n",
            "\n",
            "[1696 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEOVPRQyCjLw"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sdwcpVoZCjLw",
        "outputId": "cac9d591-a904-43d5-9896-1c40a26b78c1"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(input_size, activation='sigmoid', input_shape=(train_x.shape[1],))) # relu 사용 지양\n",
        "model.add(Dense(50,  activation='sigmoid')) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(200,  activation='sigmoid')) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(target_num, activation='sigmoid'))\n",
        "model.summary()\n",
        "model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['acc', precision, recall, f1score])\n",
        "# Fit and evaluate model \n",
        "history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1, \n",
        "                    validation_data = (test_x2, test_y2))\n",
        "#history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1, \n",
        "                    #validation_data = (now_x, now_y), callbacks = [early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 50)                1050      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 200)               10200     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 12,072\n",
            "Trainable params: 12,072\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
            "Train on 3410 samples, validate on 1695 samples\n",
            "Epoch 1/1000\n",
            "3410/3410 [==============================] - 0s 114us/sample - loss: 0.1381 - acc: 0.8370 - precision: 0.8142 - recall: 0.8614 - f1score: 0.8355 - val_loss: 0.0286 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 2/1000\n",
            "3410/3410 [==============================] - 0s 24us/sample - loss: 0.0684 - acc: 0.9326 - precision: 0.9345 - recall: 0.9353 - f1score: 0.9349 - val_loss: 0.0245 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 3/1000\n",
            "3410/3410 [==============================] - 0s 20us/sample - loss: 0.0657 - acc: 0.9326 - precision: 0.9364 - recall: 0.9358 - f1score: 0.9361 - val_loss: 0.0241 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 4/1000\n",
            "3410/3410 [==============================] - 0s 22us/sample - loss: 0.0650 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0241 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 5/1000\n",
            "3410/3410 [==============================] - 0s 20us/sample - loss: 0.0649 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0241 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 6/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0646 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0243 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 7/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0649 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0242 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 8/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0647 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0241 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 9/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0651 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0244 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 10/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0645 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0242 - val_acc: 0.9752 - val_precision: 0.9730 - val_recall: 0.9730 - val_f1score: 0.9730\n",
            "Epoch 11/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0645 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0241 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 12/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0642 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0242 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 13/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0643 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0242 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 14/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0640 - acc: 0.9326 - precision: 0.9203 - recall: 0.9203 - f1score: 0.9203 - val_loss: 0.0250 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 15/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0641 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0243 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 16/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0641 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0242 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 17/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0643 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0246 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 18/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0638 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0244 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 19/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0637 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0248 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 20/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0635 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0243 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 21/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0639 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0244 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 22/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0638 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0243 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 23/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0639 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0243 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 24/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0642 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0243 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 25/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0641 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0247 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 26/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0635 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0246 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 27/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 20us/sample - loss: 0.0639 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 28/1000\n",
            "3410/3410 [==============================] - 0s 21us/sample - loss: 0.0636 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0249 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 29/1000\n",
            "3410/3410 [==============================] - 0s 23us/sample - loss: 0.0634 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0247 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 30/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0636 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0246 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 31/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0635 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0245 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 32/1000\n",
            "3410/3410 [==============================] - 0s 22us/sample - loss: 0.0634 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0245 - val_acc: 0.9752 - val_precision: 0.9724 - val_recall: 0.9724 - val_f1score: 0.9724\n",
            "Epoch 33/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0637 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0244 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 34/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0635 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0245 - val_acc: 0.9752 - val_precision: 0.9730 - val_recall: 0.9730 - val_f1score: 0.9730\n",
            "Epoch 35/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0633 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0247 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 36/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0638 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0245 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 37/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0637 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0251 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 38/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0634 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0246 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 39/1000\n",
            "3410/3410 [==============================] - 0s 24us/sample - loss: 0.0635 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0245 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 40/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0634 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0252 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 41/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0635 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 42/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0634 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0248 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 43/1000\n",
            "3410/3410 [==============================] - 0s 20us/sample - loss: 0.0632 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0246 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 44/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0633 - acc: 0.9326 - precision: 0.9203 - recall: 0.9203 - f1score: 0.9203 - val_loss: 0.0258 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 45/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0630 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0247 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 46/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0636 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0250 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 47/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0629 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0249 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 48/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0631 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0248 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 49/1000\n",
            "3410/3410 [==============================] - 0s 21us/sample - loss: 0.0631 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0247 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 50/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0632 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 51/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0632 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0252 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 52/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0629 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0248 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 53/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0632 - acc: 0.9326 - precision: 0.9203 - recall: 0.9203 - f1score: 0.9203 - val_loss: 0.0258 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 54/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0632 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0251 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 55/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0626 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0249 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 56/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0632 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0247 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 57/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0631 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0246 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 58/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0630 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0261 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 59/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0632 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0247 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 60/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0626 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0248 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 61/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0629 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0261 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 62/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0626 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0248 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 63/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0630 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0249 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 64/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0628 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0247 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 65/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0631 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0246 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 66/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0627 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0246 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 67/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0627 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0251 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 68/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0627 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0260 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 69/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0629 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0248 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 70/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0623 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0255 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 71/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0623 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0247 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 72/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0622 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0247 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 73/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0625 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0263 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 74/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0621 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0260 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 75/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0623 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0252 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 76/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0625 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0254 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 77/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0619 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0248 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 78/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0617 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0249 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 79/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0621 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0249 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 80/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0619 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0249 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 81/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0617 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 82/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0618 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0254 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 83/1000\n",
            "3410/3410 [==============================] - 0s 23us/sample - loss: 0.0614 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0258 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 84/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0615 - acc: 0.9323 - precision: 0.9359 - recall: 0.9361 - f1score: 0.9360 - val_loss: 0.0254 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 85/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0612 - acc: 0.9326 - precision: 0.9256 - recall: 0.9256 - f1score: 0.9256 - val_loss: 0.0264 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 86/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0613 - acc: 0.9328 - precision: 0.9258 - recall: 0.9258 - f1score: 0.9258 - val_loss: 0.0262 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 87/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0616 - acc: 0.9328 - precision: 0.9256 - recall: 0.9258 - f1score: 0.9257 - val_loss: 0.0262 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 88/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0619 - acc: 0.9326 - precision: 0.9361 - recall: 0.9364 - f1score: 0.9363 - val_loss: 0.0248 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 89/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0608 - acc: 0.9326 - precision: 0.9308 - recall: 0.9308 - f1score: 0.9308 - val_loss: 0.0259 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 90/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0610 - acc: 0.9326 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0251 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 91/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0608 - acc: 0.9334 - precision: 0.9367 - recall: 0.9369 - f1score: 0.9368 - val_loss: 0.0250 - val_acc: 0.9752 - val_precision: 0.9730 - val_recall: 0.9730 - val_f1score: 0.9730\n",
            "Epoch 92/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0606 - acc: 0.9323 - precision: 0.9303 - recall: 0.9306 - f1score: 0.9304 - val_loss: 0.0257 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 93/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0608 - acc: 0.9331 - precision: 0.9311 - recall: 0.9314 - f1score: 0.9313 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 94/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0606 - acc: 0.9326 - precision: 0.9364 - recall: 0.9364 - f1score: 0.9364 - val_loss: 0.0251 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 95/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0603 - acc: 0.9326 - precision: 0.9364 - recall: 0.9364 - f1score: 0.9364 - val_loss: 0.0257 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 96/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0601 - acc: 0.9346 - precision: 0.9325 - recall: 0.9328 - f1score: 0.9326 - val_loss: 0.0256 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 97/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0610 - acc: 0.9331 - precision: 0.9311 - recall: 0.9314 - f1score: 0.9313 - val_loss: 0.0257 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 98/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0602 - acc: 0.9328 - precision: 0.9364 - recall: 0.9369 - f1score: 0.9367 - val_loss: 0.0252 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 99/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0610 - acc: 0.9331 - precision: 0.9364 - recall: 0.9369 - f1score: 0.9367 - val_loss: 0.0252 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 100/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0607 - acc: 0.9331 - precision: 0.9269 - recall: 0.9317 - f1score: 0.9292 - val_loss: 0.0260 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 101/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0602 - acc: 0.9337 - precision: 0.9367 - recall: 0.9372 - f1score: 0.9370 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 102/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0600 - acc: 0.9331 - precision: 0.9367 - recall: 0.9367 - f1score: 0.9367 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 103/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0598 - acc: 0.9340 - precision: 0.9378 - recall: 0.9378 - f1score: 0.9378 - val_loss: 0.0250 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 104/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0596 - acc: 0.9340 - precision: 0.9275 - recall: 0.9272 - f1score: 0.9274 - val_loss: 0.0257 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 105/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0599 - acc: 0.9331 - precision: 0.9309 - recall: 0.9314 - f1score: 0.9311 - val_loss: 0.0251 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 106/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0595 - acc: 0.9352 - precision: 0.9281 - recall: 0.9281 - f1score: 0.9281 - val_loss: 0.0262 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 107/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0604 - acc: 0.9320 - precision: 0.9359 - recall: 0.9361 - f1score: 0.9360 - val_loss: 0.0252 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 108/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0594 - acc: 0.9334 - precision: 0.9259 - recall: 0.9267 - f1score: 0.9263 - val_loss: 0.0264 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 109/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0595 - acc: 0.9349 - precision: 0.9384 - recall: 0.9389 - f1score: 0.9386 - val_loss: 0.0255 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 110/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0595 - acc: 0.9349 - precision: 0.9383 - recall: 0.9383 - f1score: 0.9383 - val_loss: 0.0252 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 111/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0598 - acc: 0.9331 - precision: 0.9369 - recall: 0.9369 - f1score: 0.9369 - val_loss: 0.0252 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 112/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0599 - acc: 0.9331 - precision: 0.9364 - recall: 0.9364 - f1score: 0.9364 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 113/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0597 - acc: 0.9355 - precision: 0.9386 - recall: 0.9386 - f1score: 0.9386 - val_loss: 0.0255 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 114/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0597 - acc: 0.9328 - precision: 0.9311 - recall: 0.9308 - f1score: 0.9310 - val_loss: 0.0259 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 115/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0595 - acc: 0.9346 - precision: 0.9372 - recall: 0.9375 - f1score: 0.9374 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 116/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0595 - acc: 0.9346 - precision: 0.9378 - recall: 0.9381 - f1score: 0.9379 - val_loss: 0.0252 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 117/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0591 - acc: 0.9346 - precision: 0.9381 - recall: 0.9381 - f1score: 0.9381 - val_loss: 0.0258 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 118/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0587 - acc: 0.9349 - precision: 0.9380 - recall: 0.9378 - f1score: 0.9379 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 119/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0596 - acc: 0.9349 - precision: 0.9383 - recall: 0.9381 - f1score: 0.9382 - val_loss: 0.0250 - val_acc: 0.9752 - val_precision: 0.9742 - val_recall: 0.9742 - val_f1score: 0.9742\n",
            "Epoch 120/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0583 - acc: 0.9352 - precision: 0.9331 - recall: 0.9333 - f1score: 0.9332 - val_loss: 0.0260 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 121/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0596 - acc: 0.9334 - precision: 0.9266 - recall: 0.9261 - f1score: 0.9264 - val_loss: 0.0255 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 122/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0590 - acc: 0.9340 - precision: 0.9375 - recall: 0.9375 - f1score: 0.9375 - val_loss: 0.0252 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 123/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0589 - acc: 0.9361 - precision: 0.9334 - recall: 0.9342 - f1score: 0.9338 - val_loss: 0.0258 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 124/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0586 - acc: 0.9349 - precision: 0.9386 - recall: 0.9389 - f1score: 0.9387 - val_loss: 0.0254 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 125/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0594 - acc: 0.9340 - precision: 0.9375 - recall: 0.9369 - f1score: 0.9372 - val_loss: 0.0254 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 126/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0584 - acc: 0.9361 - precision: 0.9344 - recall: 0.9336 - f1score: 0.9340 - val_loss: 0.0256 - val_acc: 0.9752 - val_precision: 0.9730 - val_recall: 0.9730 - val_f1score: 0.9730\n",
            "Epoch 127/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0582 - acc: 0.9367 - precision: 0.9350 - recall: 0.9347 - f1score: 0.9349 - val_loss: 0.0262 - val_acc: 0.9740 - val_precision: 0.9743 - val_recall: 0.9749 - val_f1score: 0.9746\n",
            "Epoch 128/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0583 - acc: 0.9364 - precision: 0.9395 - recall: 0.9403 - f1score: 0.9399 - val_loss: 0.0251 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 129/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0594 - acc: 0.9340 - precision: 0.9370 - recall: 0.9378 - f1score: 0.9374 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 130/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0585 - acc: 0.9355 - precision: 0.9336 - recall: 0.9342 - f1score: 0.9339 - val_loss: 0.0260 - val_acc: 0.9746 - val_precision: 0.9749 - val_recall: 0.9749 - val_f1score: 0.9749\n",
            "Epoch 131/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0578 - acc: 0.9361 - precision: 0.9392 - recall: 0.9394 - f1score: 0.9393 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9736 - val_recall: 0.9736 - val_f1score: 0.9736\n",
            "Epoch 132/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0582 - acc: 0.9349 - precision: 0.9336 - recall: 0.9339 - f1score: 0.9338 - val_loss: 0.0255 - val_acc: 0.9752 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1score: 0.9754\n",
            "Epoch 133/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0585 - acc: 0.9349 - precision: 0.9383 - recall: 0.9383 - f1score: 0.9383 - val_loss: 0.0251 - val_acc: 0.9752 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1score: 0.9761\n",
            "Epoch 134/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0575 - acc: 0.9352 - precision: 0.9383 - recall: 0.9383 - f1score: 0.9383 - val_loss: 0.0260 - val_acc: 0.9740 - val_precision: 0.9737 - val_recall: 0.9737 - val_f1score: 0.9737\n",
            "Epoch 135/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0590 - acc: 0.9337 - precision: 0.9211 - recall: 0.9214 - f1score: 0.9213 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 136/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0582 - acc: 0.9343 - precision: 0.9328 - recall: 0.9328 - f1score: 0.9328 - val_loss: 0.0259 - val_acc: 0.9746 - val_precision: 0.9743 - val_recall: 0.9743 - val_f1score: 0.9743\n",
            "Epoch 137/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0579 - acc: 0.9337 - precision: 0.9372 - recall: 0.9372 - f1score: 0.9372 - val_loss: 0.0254 - val_acc: 0.9752 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1score: 0.9767\n",
            "Epoch 138/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0588 - acc: 0.9358 - precision: 0.9389 - recall: 0.9383 - f1score: 0.9386 - val_loss: 0.0256 - val_acc: 0.9746 - val_precision: 0.9743 - val_recall: 0.9743 - val_f1score: 0.9743\n",
            "Epoch 139/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0581 - acc: 0.9352 - precision: 0.9392 - recall: 0.9392 - f1score: 0.9392 - val_loss: 0.0256 - val_acc: 0.9740 - val_precision: 0.9737 - val_recall: 0.9737 - val_f1score: 0.9737\n",
            "Epoch 140/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0589 - acc: 0.9355 - precision: 0.9331 - recall: 0.9333 - f1score: 0.9332 - val_loss: 0.0263 - val_acc: 0.9729 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 141/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0580 - acc: 0.9361 - precision: 0.9342 - recall: 0.9342 - f1score: 0.9342 - val_loss: 0.0261 - val_acc: 0.9729 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 142/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0583 - acc: 0.9355 - precision: 0.9381 - recall: 0.9389 - f1score: 0.9385 - val_loss: 0.0259 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 143/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0579 - acc: 0.9349 - precision: 0.9386 - recall: 0.9383 - f1score: 0.9385 - val_loss: 0.0256 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 144/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0579 - acc: 0.9352 - precision: 0.9384 - recall: 0.9386 - f1score: 0.9385 - val_loss: 0.0260 - val_acc: 0.9729 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 145/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0578 - acc: 0.9340 - precision: 0.9381 - recall: 0.9381 - f1score: 0.9381 - val_loss: 0.0257 - val_acc: 0.9735 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 146/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0578 - acc: 0.9361 - precision: 0.9387 - recall: 0.9394 - f1score: 0.9391 - val_loss: 0.0258 - val_acc: 0.9735 - val_precision: 0.9719 - val_recall: 0.9719 - val_f1score: 0.9719\n",
            "Epoch 147/1000\n",
            "3410/3410 [==============================] - ETA: 0s - loss: 0.0758 - acc: 0.9150 - precision: 0.9150 - recall: 0.9150 - f1score: 0.91 - 0s 17us/sample - loss: 0.0585 - acc: 0.9343 - precision: 0.9378 - recall: 0.9378 - f1score: 0.9378 - val_loss: 0.0255 - val_acc: 0.9735 - val_precision: 0.9744 - val_recall: 0.9738 - val_f1score: 0.9741\n",
            "Epoch 148/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0579 - acc: 0.9370 - precision: 0.9400 - recall: 0.9403 - f1score: 0.9401 - val_loss: 0.0254 - val_acc: 0.9746 - val_precision: 0.9737 - val_recall: 0.9737 - val_f1score: 0.9737\n",
            "Epoch 149/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0580 - acc: 0.9367 - precision: 0.9345 - recall: 0.9350 - f1score: 0.9347 - val_loss: 0.0256 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 150/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0582 - acc: 0.9358 - precision: 0.9394 - recall: 0.9392 - f1score: 0.9393 - val_loss: 0.0261 - val_acc: 0.9729 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 151/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0570 - acc: 0.9370 - precision: 0.9350 - recall: 0.9350 - f1score: 0.9350 - val_loss: 0.0262 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 152/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0574 - acc: 0.9381 - precision: 0.9408 - recall: 0.9403 - f1score: 0.9405 - val_loss: 0.0253 - val_acc: 0.9752 - val_precision: 0.9748 - val_recall: 0.9748 - val_f1score: 0.9748\n",
            "Epoch 153/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0566 - acc: 0.9378 - precision: 0.9411 - recall: 0.9414 - f1score: 0.9413 - val_loss: 0.0263 - val_acc: 0.9723 - val_precision: 0.9739 - val_recall: 0.9739 - val_f1score: 0.9739\n",
            "Epoch 154/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0572 - acc: 0.9355 - precision: 0.9391 - recall: 0.9389 - f1score: 0.9390 - val_loss: 0.0265 - val_acc: 0.9723 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n",
            "Epoch 155/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0568 - acc: 0.9372 - precision: 0.9406 - recall: 0.9408 - f1score: 0.9407 - val_loss: 0.0268 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 156/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0575 - acc: 0.9378 - precision: 0.9411 - recall: 0.9406 - f1score: 0.9408 - val_loss: 0.0266 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 157/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0575 - acc: 0.9370 - precision: 0.9405 - recall: 0.9403 - f1score: 0.9404 - val_loss: 0.0257 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 158/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0573 - acc: 0.9370 - precision: 0.9348 - recall: 0.9353 - f1score: 0.9350 - val_loss: 0.0269 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 159/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0572 - acc: 0.9364 - precision: 0.9392 - recall: 0.9397 - f1score: 0.9395 - val_loss: 0.0257 - val_acc: 0.9735 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 160/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0566 - acc: 0.9370 - precision: 0.9297 - recall: 0.9297 - f1score: 0.9297 - val_loss: 0.0270 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 161/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0574 - acc: 0.9358 - precision: 0.9344 - recall: 0.9339 - f1score: 0.9341 - val_loss: 0.0254 - val_acc: 0.9740 - val_precision: 0.9713 - val_recall: 0.9719 - val_f1score: 0.9716\n",
            "Epoch 162/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0564 - acc: 0.9372 - precision: 0.9358 - recall: 0.9347 - f1score: 0.9352 - val_loss: 0.0269 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 163/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0579 - acc: 0.9346 - precision: 0.9378 - recall: 0.9383 - f1score: 0.9381 - val_loss: 0.0265 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 164/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0575 - acc: 0.9370 - precision: 0.9400 - recall: 0.9403 - f1score: 0.9401 - val_loss: 0.0257 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 165/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0575 - acc: 0.9358 - precision: 0.9392 - recall: 0.9394 - f1score: 0.9393 - val_loss: 0.0256 - val_acc: 0.9735 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 166/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0566 - acc: 0.9367 - precision: 0.9351 - recall: 0.9356 - f1score: 0.9353 - val_loss: 0.0259 - val_acc: 0.9735 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 167/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0569 - acc: 0.9364 - precision: 0.9344 - recall: 0.9342 - f1score: 0.9343 - val_loss: 0.0263 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 168/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0564 - acc: 0.9378 - precision: 0.9358 - recall: 0.9356 - f1score: 0.9357 - val_loss: 0.0269 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 169/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0569 - acc: 0.9364 - precision: 0.9399 - recall: 0.9392 - f1score: 0.9396 - val_loss: 0.0264 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 170/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0565 - acc: 0.9372 - precision: 0.9403 - recall: 0.9408 - f1score: 0.9406 - val_loss: 0.0259 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 171/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0567 - acc: 0.9378 - precision: 0.9361 - recall: 0.9358 - f1score: 0.9360 - val_loss: 0.0271 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 172/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0573 - acc: 0.9372 - precision: 0.9403 - recall: 0.9406 - f1score: 0.9404 - val_loss: 0.0261 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 173/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0564 - acc: 0.9384 - precision: 0.9422 - recall: 0.9417 - f1score: 0.9419 - val_loss: 0.0262 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 174/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0564 - acc: 0.9375 - precision: 0.9408 - recall: 0.9406 - f1score: 0.9407 - val_loss: 0.0263 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 175/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0567 - acc: 0.9384 - precision: 0.9364 - recall: 0.9358 - f1score: 0.9361 - val_loss: 0.0264 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 176/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0564 - acc: 0.9390 - precision: 0.9316 - recall: 0.9311 - f1score: 0.9314 - val_loss: 0.0274 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 177/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0562 - acc: 0.9387 - precision: 0.9414 - recall: 0.9422 - f1score: 0.9418 - val_loss: 0.0261 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 178/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0565 - acc: 0.9381 - precision: 0.9411 - recall: 0.9414 - f1score: 0.9413 - val_loss: 0.0263 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 179/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0563 - acc: 0.9375 - precision: 0.9408 - recall: 0.9411 - f1score: 0.9410 - val_loss: 0.0254 - val_acc: 0.9740 - val_precision: 0.9731 - val_recall: 0.9731 - val_f1score: 0.9731\n",
            "Epoch 180/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0571 - acc: 0.9367 - precision: 0.9297 - recall: 0.9292 - f1score: 0.9294 - val_loss: 0.0275 - val_acc: 0.9723 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n",
            "Epoch 181/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0555 - acc: 0.9384 - precision: 0.9414 - recall: 0.9411 - f1score: 0.9412 - val_loss: 0.0260 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 182/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0561 - acc: 0.9378 - precision: 0.9413 - recall: 0.9406 - f1score: 0.9409 - val_loss: 0.0262 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 183/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0564 - acc: 0.9384 - precision: 0.9367 - recall: 0.9364 - f1score: 0.9365 - val_loss: 0.0272 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 184/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0565 - acc: 0.9370 - precision: 0.9403 - recall: 0.9406 - f1score: 0.9404 - val_loss: 0.0268 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 185/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0559 - acc: 0.9393 - precision: 0.9428 - recall: 0.9431 - f1score: 0.9429 - val_loss: 0.0264 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 186/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0561 - acc: 0.9384 - precision: 0.9414 - recall: 0.9414 - f1score: 0.9414 - val_loss: 0.0272 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 187/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0559 - acc: 0.9381 - precision: 0.9417 - recall: 0.9422 - f1score: 0.9420 - val_loss: 0.0263 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 188/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0564 - acc: 0.9375 - precision: 0.9411 - recall: 0.9406 - f1score: 0.9408 - val_loss: 0.0264 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 189/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0564 - acc: 0.9375 - precision: 0.9408 - recall: 0.9406 - f1score: 0.9407 - val_loss: 0.0264 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9727 - val_f1score: 0.9729\n",
            "Epoch 190/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0564 - acc: 0.9378 - precision: 0.9300 - recall: 0.9300 - f1score: 0.9300 - val_loss: 0.0274 - val_acc: 0.9723 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n",
            "Epoch 191/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0566 - acc: 0.9372 - precision: 0.9295 - recall: 0.9294 - f1score: 0.9294 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 192/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0556 - acc: 0.9399 - precision: 0.9380 - recall: 0.9381 - f1score: 0.9380 - val_loss: 0.0266 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 193/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0560 - acc: 0.9387 - precision: 0.9422 - recall: 0.9422 - f1score: 0.9422 - val_loss: 0.0264 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 194/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0561 - acc: 0.9393 - precision: 0.9370 - recall: 0.9372 - f1score: 0.9371 - val_loss: 0.0269 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 195/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0555 - acc: 0.9387 - precision: 0.9419 - recall: 0.9419 - f1score: 0.9419 - val_loss: 0.0268 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 196/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0557 - acc: 0.9390 - precision: 0.9370 - recall: 0.9372 - f1score: 0.9371 - val_loss: 0.0270 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 197/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0557 - acc: 0.9393 - precision: 0.9317 - recall: 0.9325 - f1score: 0.9321 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 198/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0558 - acc: 0.9375 - precision: 0.9411 - recall: 0.9411 - f1score: 0.9411 - val_loss: 0.0262 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 199/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0566 - acc: 0.9384 - precision: 0.9416 - recall: 0.9414 - f1score: 0.9415 - val_loss: 0.0268 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 200/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0562 - acc: 0.9375 - precision: 0.9358 - recall: 0.9358 - f1score: 0.9358 - val_loss: 0.0271 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 201/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0553 - acc: 0.9390 - precision: 0.9272 - recall: 0.9264 - f1score: 0.9268 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 202/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0560 - acc: 0.9393 - precision: 0.9423 - recall: 0.9428 - f1score: 0.9425 - val_loss: 0.0263 - val_acc: 0.9729 - val_precision: 0.9744 - val_recall: 0.9744 - val_f1score: 0.9744\n",
            "Epoch 203/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0555 - acc: 0.9381 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0277 - val_acc: 0.9723 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n",
            "Epoch 204/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0552 - acc: 0.9393 - precision: 0.9435 - recall: 0.9422 - f1score: 0.9429 - val_loss: 0.0273 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 205/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0558 - acc: 0.9384 - precision: 0.9417 - recall: 0.9419 - f1score: 0.9418 - val_loss: 0.0269 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 206/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0561 - acc: 0.9372 - precision: 0.9408 - recall: 0.9408 - f1score: 0.9408 - val_loss: 0.0262 - val_acc: 0.9735 - val_precision: 0.9750 - val_recall: 0.9750 - val_f1score: 0.9750\n",
            "Epoch 207/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0560 - acc: 0.9384 - precision: 0.9361 - recall: 0.9364 - f1score: 0.9363 - val_loss: 0.0273 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 208/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0552 - acc: 0.9402 - precision: 0.9433 - recall: 0.9431 - f1score: 0.9432 - val_loss: 0.0266 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 209/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0556 - acc: 0.9390 - precision: 0.9423 - recall: 0.9431 - f1score: 0.9427 - val_loss: 0.0263 - val_acc: 0.9729 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 210/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0549 - acc: 0.9408 - precision: 0.9441 - recall: 0.9439 - f1score: 0.9440 - val_loss: 0.0264 - val_acc: 0.9723 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n",
            "Epoch 211/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0553 - acc: 0.9393 - precision: 0.9422 - recall: 0.9428 - f1score: 0.9425 - val_loss: 0.0267 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 212/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0557 - acc: 0.9399 - precision: 0.9428 - recall: 0.9431 - f1score: 0.9429 - val_loss: 0.0264 - val_acc: 0.9729 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 213/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0555 - acc: 0.9405 - precision: 0.9439 - recall: 0.9439 - f1score: 0.9439 - val_loss: 0.0267 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 214/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0562 - acc: 0.9378 - precision: 0.9356 - recall: 0.9358 - f1score: 0.9357 - val_loss: 0.0269 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 215/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0546 - acc: 0.9408 - precision: 0.9384 - recall: 0.9386 - f1score: 0.9385 - val_loss: 0.0274 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 216/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0559 - acc: 0.9370 - precision: 0.9350 - recall: 0.9350 - f1score: 0.9350 - val_loss: 0.0274 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 217/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0551 - acc: 0.9384 - precision: 0.9314 - recall: 0.9314 - f1score: 0.9314 - val_loss: 0.0266 - val_acc: 0.9735 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 218/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0549 - acc: 0.9396 - precision: 0.9380 - recall: 0.9378 - f1score: 0.9379 - val_loss: 0.0269 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 219/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0562 - acc: 0.9384 - precision: 0.9358 - recall: 0.9361 - f1score: 0.9360 - val_loss: 0.0272 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 220/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0560 - acc: 0.9381 - precision: 0.9309 - recall: 0.9311 - f1score: 0.9310 - val_loss: 0.0285 - val_acc: 0.9717 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 221/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0551 - acc: 0.9384 - precision: 0.9364 - recall: 0.9364 - f1score: 0.9364 - val_loss: 0.0273 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 222/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0561 - acc: 0.9370 - precision: 0.9295 - recall: 0.9300 - f1score: 0.9297 - val_loss: 0.0284 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 223/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0546 - acc: 0.9396 - precision: 0.9372 - recall: 0.9372 - f1score: 0.9372 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 224/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0554 - acc: 0.9387 - precision: 0.9372 - recall: 0.9361 - f1score: 0.9366 - val_loss: 0.0277 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 225/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0553 - acc: 0.9387 - precision: 0.9367 - recall: 0.9367 - f1score: 0.9367 - val_loss: 0.0266 - val_acc: 0.9729 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 226/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0552 - acc: 0.9390 - precision: 0.9425 - recall: 0.9425 - f1score: 0.9425 - val_loss: 0.0264 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 227/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0559 - acc: 0.9390 - precision: 0.9314 - recall: 0.9314 - f1score: 0.9314 - val_loss: 0.0277 - val_acc: 0.9729 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 228/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0549 - acc: 0.9408 - precision: 0.9383 - recall: 0.9381 - f1score: 0.9382 - val_loss: 0.0271 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 229/1000\n",
            "3410/3410 [==============================] - 0s 24us/sample - loss: 0.0553 - acc: 0.9399 - precision: 0.9428 - recall: 0.9431 - f1score: 0.9429 - val_loss: 0.0269 - val_acc: 0.9729 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n",
            "Epoch 230/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0552 - acc: 0.9387 - precision: 0.9314 - recall: 0.9317 - f1score: 0.9315 - val_loss: 0.0283 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 231/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0550 - acc: 0.9396 - precision: 0.9377 - recall: 0.9369 - f1score: 0.9373 - val_loss: 0.0277 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 232/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0543 - acc: 0.9413 - precision: 0.9439 - recall: 0.9444 - f1score: 0.9442 - val_loss: 0.0266 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 233/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0549 - acc: 0.9399 - precision: 0.9378 - recall: 0.9375 - f1score: 0.9376 - val_loss: 0.0273 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 234/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0552 - acc: 0.9384 - precision: 0.9362 - recall: 0.9367 - f1score: 0.9364 - val_loss: 0.0264 - val_acc: 0.9735 - val_precision: 0.9750 - val_recall: 0.9750 - val_f1score: 0.9750\n",
            "Epoch 235/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0545 - acc: 0.9405 - precision: 0.9436 - recall: 0.9436 - f1score: 0.9436 - val_loss: 0.0264 - val_acc: 0.9735 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 236/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0536 - acc: 0.9419 - precision: 0.9450 - recall: 0.9450 - f1score: 0.9450 - val_loss: 0.0260 - val_acc: 0.9735 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 237/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0541 - acc: 0.9411 - precision: 0.9386 - recall: 0.9386 - f1score: 0.9386 - val_loss: 0.0282 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 238/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0550 - acc: 0.9405 - precision: 0.9439 - recall: 0.9436 - f1score: 0.9437 - val_loss: 0.0267 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 239/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0545 - acc: 0.9411 - precision: 0.9331 - recall: 0.9336 - f1score: 0.9334 - val_loss: 0.0271 - val_acc: 0.9735 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 240/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0549 - acc: 0.9399 - precision: 0.9378 - recall: 0.9378 - f1score: 0.9378 - val_loss: 0.0267 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 241/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0556 - acc: 0.9405 - precision: 0.9383 - recall: 0.9383 - f1score: 0.9383 - val_loss: 0.0262 - val_acc: 0.9735 - val_precision: 0.9744 - val_recall: 0.9744 - val_f1score: 0.9744\n",
            "Epoch 242/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0553 - acc: 0.9387 - precision: 0.9416 - recall: 0.9414 - f1score: 0.9415 - val_loss: 0.0269 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 243/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0542 - acc: 0.9422 - precision: 0.9397 - recall: 0.9400 - f1score: 0.9399 - val_loss: 0.0274 - val_acc: 0.9729 - val_precision: 0.9744 - val_recall: 0.9744 - val_f1score: 0.9744\n",
            "Epoch 244/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0543 - acc: 0.9405 - precision: 0.9433 - recall: 0.9436 - f1score: 0.9435 - val_loss: 0.0265 - val_acc: 0.9735 - val_precision: 0.9725 - val_recall: 0.9725 - val_f1score: 0.9725\n",
            "Epoch 245/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0556 - acc: 0.9390 - precision: 0.9420 - recall: 0.9425 - f1score: 0.9422 - val_loss: 0.0271 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 246/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0558 - acc: 0.9384 - precision: 0.9364 - recall: 0.9364 - f1score: 0.9364 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 247/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0550 - acc: 0.9402 - precision: 0.9375 - recall: 0.9381 - f1score: 0.9378 - val_loss: 0.0267 - val_acc: 0.9729 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 248/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0544 - acc: 0.9405 - precision: 0.9383 - recall: 0.9383 - f1score: 0.9383 - val_loss: 0.0271 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 249/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0554 - acc: 0.9396 - precision: 0.9375 - recall: 0.9375 - f1score: 0.9375 - val_loss: 0.0270 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 250/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0556 - acc: 0.9399 - precision: 0.9378 - recall: 0.9375 - f1score: 0.9376 - val_loss: 0.0275 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 251/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0555 - acc: 0.9399 - precision: 0.9430 - recall: 0.9428 - f1score: 0.9429 - val_loss: 0.0267 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 252/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0547 - acc: 0.9402 - precision: 0.9436 - recall: 0.9431 - f1score: 0.9433 - val_loss: 0.0269 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 253/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0540 - acc: 0.9411 - precision: 0.9389 - recall: 0.9389 - f1score: 0.9389 - val_loss: 0.0268 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 254/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0549 - acc: 0.9402 - precision: 0.9431 - recall: 0.9433 - f1score: 0.9432 - val_loss: 0.0285 - val_acc: 0.9711 - val_precision: 0.9703 - val_recall: 0.9703 - val_f1score: 0.9703\n",
            "Epoch 255/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0534 - acc: 0.9408 - precision: 0.9386 - recall: 0.9389 - f1score: 0.9388 - val_loss: 0.0272 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 256/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0547 - acc: 0.9393 - precision: 0.9372 - recall: 0.9372 - f1score: 0.9372 - val_loss: 0.0281 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 257/1000\n",
            "3410/3410 [==============================] - 0s 24us/sample - loss: 0.0551 - acc: 0.9405 - precision: 0.9383 - recall: 0.9383 - f1score: 0.9383 - val_loss: 0.0288 - val_acc: 0.9723 - val_precision: 0.9739 - val_recall: 0.9739 - val_f1score: 0.9739\n",
            "Epoch 258/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0549 - acc: 0.9393 - precision: 0.9425 - recall: 0.9422 - f1score: 0.9424 - val_loss: 0.0263 - val_acc: 0.9735 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 259/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0542 - acc: 0.9416 - precision: 0.9445 - recall: 0.9444 - f1score: 0.9444 - val_loss: 0.0263 - val_acc: 0.9735 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 260/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0545 - acc: 0.9411 - precision: 0.9389 - recall: 0.9383 - f1score: 0.9386 - val_loss: 0.0274 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 261/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0554 - acc: 0.9390 - precision: 0.9422 - recall: 0.9425 - f1score: 0.9424 - val_loss: 0.0267 - val_acc: 0.9735 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 262/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0547 - acc: 0.9405 - precision: 0.9381 - recall: 0.9383 - f1score: 0.9382 - val_loss: 0.0276 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 263/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0545 - acc: 0.9396 - precision: 0.9428 - recall: 0.9428 - f1score: 0.9428 - val_loss: 0.0266 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 264/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0545 - acc: 0.9413 - precision: 0.9394 - recall: 0.9392 - f1score: 0.9393 - val_loss: 0.0273 - val_acc: 0.9729 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 265/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0535 - acc: 0.9413 - precision: 0.9447 - recall: 0.9444 - f1score: 0.9446 - val_loss: 0.0275 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 266/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0536 - acc: 0.9428 - precision: 0.9456 - recall: 0.9458 - f1score: 0.9457 - val_loss: 0.0271 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 267/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0550 - acc: 0.9399 - precision: 0.9436 - recall: 0.9428 - f1score: 0.9432 - val_loss: 0.0267 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 268/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0538 - acc: 0.9422 - precision: 0.9400 - recall: 0.9403 - f1score: 0.9401 - val_loss: 0.0276 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 269/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0548 - acc: 0.9419 - precision: 0.9450 - recall: 0.9450 - f1score: 0.9450 - val_loss: 0.0263 - val_acc: 0.9735 - val_precision: 0.9744 - val_recall: 0.9744 - val_f1score: 0.9744\n",
            "Epoch 270/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0539 - acc: 0.9411 - precision: 0.9447 - recall: 0.9439 - f1score: 0.9443 - val_loss: 0.0275 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 271/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0546 - acc: 0.9399 - precision: 0.9328 - recall: 0.9328 - f1score: 0.9328 - val_loss: 0.0269 - val_acc: 0.9735 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 272/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0544 - acc: 0.9402 - precision: 0.9381 - recall: 0.9381 - f1score: 0.9381 - val_loss: 0.0283 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 273/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0536 - acc: 0.9408 - precision: 0.9439 - recall: 0.9436 - f1score: 0.9437 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9732 - val_recall: 0.9727 - val_f1score: 0.9729\n",
            "Epoch 274/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0548 - acc: 0.9402 - precision: 0.9380 - recall: 0.9378 - f1score: 0.9379 - val_loss: 0.0272 - val_acc: 0.9735 - val_precision: 0.9750 - val_recall: 0.9750 - val_f1score: 0.9750\n",
            "Epoch 275/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0548 - acc: 0.9399 - precision: 0.9431 - recall: 0.9431 - f1score: 0.9431 - val_loss: 0.0267 - val_acc: 0.9735 - val_precision: 0.9744 - val_recall: 0.9744 - val_f1score: 0.9744\n",
            "Epoch 276/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0547 - acc: 0.9393 - precision: 0.9425 - recall: 0.9428 - f1score: 0.9427 - val_loss: 0.0271 - val_acc: 0.9729 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 277/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0544 - acc: 0.9402 - precision: 0.9433 - recall: 0.9431 - f1score: 0.9432 - val_loss: 0.0266 - val_acc: 0.9735 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 278/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0541 - acc: 0.9405 - precision: 0.9433 - recall: 0.9433 - f1score: 0.9433 - val_loss: 0.0269 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 279/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0543 - acc: 0.9405 - precision: 0.9378 - recall: 0.9386 - f1score: 0.9382 - val_loss: 0.0265 - val_acc: 0.9735 - val_precision: 0.9744 - val_recall: 0.9744 - val_f1score: 0.9744\n",
            "Epoch 280/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0547 - acc: 0.9402 - precision: 0.9381 - recall: 0.9381 - f1score: 0.9381 - val_loss: 0.0263 - val_acc: 0.9735 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1score: 0.9738\n",
            "Epoch 281/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0541 - acc: 0.9405 - precision: 0.9436 - recall: 0.9442 - f1score: 0.9439 - val_loss: 0.0273 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 282/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0541 - acc: 0.9402 - precision: 0.9381 - recall: 0.9381 - f1score: 0.9381 - val_loss: 0.0270 - val_acc: 0.9729 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 283/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0539 - acc: 0.9408 - precision: 0.9281 - recall: 0.9283 - f1score: 0.9282 - val_loss: 0.0269 - val_acc: 0.9735 - val_precision: 0.9744 - val_recall: 0.9744 - val_f1score: 0.9744\n",
            "Epoch 284/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0545 - acc: 0.9396 - precision: 0.9428 - recall: 0.9428 - f1score: 0.9428 - val_loss: 0.0270 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 285/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0538 - acc: 0.9422 - precision: 0.9294 - recall: 0.9294 - f1score: 0.9294 - val_loss: 0.0281 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 286/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0538 - acc: 0.9402 - precision: 0.9436 - recall: 0.9436 - f1score: 0.9436 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 287/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0542 - acc: 0.9411 - precision: 0.9389 - recall: 0.9386 - f1score: 0.9387 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 288/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0545 - acc: 0.9416 - precision: 0.9447 - recall: 0.9447 - f1score: 0.9447 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 289/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0543 - acc: 0.9405 - precision: 0.9434 - recall: 0.9436 - f1score: 0.9435 - val_loss: 0.0265 - val_acc: 0.9735 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 290/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0547 - acc: 0.9384 - precision: 0.9417 - recall: 0.9422 - f1score: 0.9420 - val_loss: 0.0271 - val_acc: 0.9729 - val_precision: 0.9726 - val_recall: 0.9726 - val_f1score: 0.9726\n",
            "Epoch 291/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0535 - acc: 0.9413 - precision: 0.9450 - recall: 0.9447 - f1score: 0.9449 - val_loss: 0.0272 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 292/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0543 - acc: 0.9396 - precision: 0.9375 - recall: 0.9378 - f1score: 0.9376 - val_loss: 0.0278 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 293/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0537 - acc: 0.9402 - precision: 0.9275 - recall: 0.9275 - f1score: 0.9275 - val_loss: 0.0272 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 294/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0543 - acc: 0.9393 - precision: 0.9372 - recall: 0.9375 - f1score: 0.9374 - val_loss: 0.0280 - val_acc: 0.9723 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n",
            "Epoch 295/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0538 - acc: 0.9411 - precision: 0.9447 - recall: 0.9439 - f1score: 0.9443 - val_loss: 0.0274 - val_acc: 0.9723 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n",
            "Epoch 296/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0537 - acc: 0.9405 - precision: 0.9437 - recall: 0.9442 - f1score: 0.9439 - val_loss: 0.0275 - val_acc: 0.9723 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n",
            "Epoch 297/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0538 - acc: 0.9419 - precision: 0.9450 - recall: 0.9447 - f1score: 0.9449 - val_loss: 0.0270 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 298/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0540 - acc: 0.9408 - precision: 0.9331 - recall: 0.9331 - f1score: 0.9331 - val_loss: 0.0287 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 299/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0539 - acc: 0.9416 - precision: 0.9342 - recall: 0.9342 - f1score: 0.9342 - val_loss: 0.0282 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 300/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0540 - acc: 0.9399 - precision: 0.9383 - recall: 0.9378 - f1score: 0.9380 - val_loss: 0.0277 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 301/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0543 - acc: 0.9411 - precision: 0.9389 - recall: 0.9392 - f1score: 0.9390 - val_loss: 0.0280 - val_acc: 0.9723 - val_precision: 0.9702 - val_recall: 0.9702 - val_f1score: 0.9702\n",
            "Epoch 302/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0536 - acc: 0.9402 - precision: 0.9436 - recall: 0.9433 - f1score: 0.9435 - val_loss: 0.0274 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 303/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0537 - acc: 0.9405 - precision: 0.9386 - recall: 0.9383 - f1score: 0.9385 - val_loss: 0.0295 - val_acc: 0.9717 - val_precision: 0.9709 - val_recall: 0.9709 - val_f1score: 0.9709\n",
            "Epoch 304/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0539 - acc: 0.9411 - precision: 0.9442 - recall: 0.9442 - f1score: 0.9442 - val_loss: 0.0270 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 305/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0537 - acc: 0.9408 - precision: 0.9436 - recall: 0.9436 - f1score: 0.9436 - val_loss: 0.0283 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 306/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0541 - acc: 0.9399 - precision: 0.9325 - recall: 0.9325 - f1score: 0.9325 - val_loss: 0.0277 - val_acc: 0.9723 - val_precision: 0.9702 - val_recall: 0.9702 - val_f1score: 0.9702\n",
            "Epoch 307/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0536 - acc: 0.9411 - precision: 0.9389 - recall: 0.9386 - f1score: 0.9387 - val_loss: 0.0270 - val_acc: 0.9729 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n",
            "Epoch 308/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0544 - acc: 0.9399 - precision: 0.9431 - recall: 0.9433 - f1score: 0.9432 - val_loss: 0.0268 - val_acc: 0.9729 - val_precision: 0.9744 - val_recall: 0.9744 - val_f1score: 0.9744\n",
            "Epoch 309/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0528 - acc: 0.9434 - precision: 0.9469 - recall: 0.9464 - f1score: 0.9466 - val_loss: 0.0277 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 310/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0538 - acc: 0.9411 - precision: 0.9439 - recall: 0.9439 - f1score: 0.9439 - val_loss: 0.0270 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 311/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0539 - acc: 0.9413 - precision: 0.9445 - recall: 0.9447 - f1score: 0.9446 - val_loss: 0.0272 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 312/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0531 - acc: 0.9416 - precision: 0.9394 - recall: 0.9392 - f1score: 0.9393 - val_loss: 0.0274 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 313/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0534 - acc: 0.9413 - precision: 0.9389 - recall: 0.9389 - f1score: 0.9389 - val_loss: 0.0287 - val_acc: 0.9717 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 314/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0532 - acc: 0.9419 - precision: 0.9344 - recall: 0.9344 - f1score: 0.9344 - val_loss: 0.0282 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 315/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0530 - acc: 0.9416 - precision: 0.9447 - recall: 0.9447 - f1score: 0.9447 - val_loss: 0.0281 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 316/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0540 - acc: 0.9416 - precision: 0.9442 - recall: 0.9444 - f1score: 0.9443 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9708 - val_recall: 0.9708 - val_f1score: 0.9708\n",
            "Epoch 317/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0531 - acc: 0.9416 - precision: 0.9447 - recall: 0.9447 - f1score: 0.9447 - val_loss: 0.0270 - val_acc: 0.9723 - val_precision: 0.9739 - val_recall: 0.9739 - val_f1score: 0.9739\n",
            "Epoch 318/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0531 - acc: 0.9413 - precision: 0.9444 - recall: 0.9444 - f1score: 0.9444 - val_loss: 0.0272 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 319/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0536 - acc: 0.9402 - precision: 0.9381 - recall: 0.9381 - f1score: 0.9381 - val_loss: 0.0279 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 320/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0524 - acc: 0.9425 - precision: 0.9458 - recall: 0.9456 - f1score: 0.9457 - val_loss: 0.0273 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 321/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0529 - acc: 0.9419 - precision: 0.9397 - recall: 0.9394 - f1score: 0.9396 - val_loss: 0.0284 - val_acc: 0.9717 - val_precision: 0.9696 - val_recall: 0.9696 - val_f1score: 0.9696\n",
            "Epoch 322/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0534 - acc: 0.9419 - precision: 0.9397 - recall: 0.9394 - f1score: 0.9396 - val_loss: 0.0280 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 323/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0522 - acc: 0.9437 - precision: 0.9469 - recall: 0.9467 - f1score: 0.9468 - val_loss: 0.0280 - val_acc: 0.9717 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 324/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0537 - acc: 0.9413 - precision: 0.9444 - recall: 0.9442 - f1score: 0.9443 - val_loss: 0.0272 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 325/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0527 - acc: 0.9437 - precision: 0.9414 - recall: 0.9414 - f1score: 0.9414 - val_loss: 0.0288 - val_acc: 0.9717 - val_precision: 0.9721 - val_recall: 0.9721 - val_f1score: 0.9721\n",
            "Epoch 326/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0530 - acc: 0.9413 - precision: 0.9444 - recall: 0.9444 - f1score: 0.9444 - val_loss: 0.0283 - val_acc: 0.9717 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 327/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0541 - acc: 0.9396 - precision: 0.9428 - recall: 0.9428 - f1score: 0.9428 - val_loss: 0.0274 - val_acc: 0.9723 - val_precision: 0.9739 - val_recall: 0.9739 - val_f1score: 0.9739\n",
            "Epoch 328/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0524 - acc: 0.9431 - precision: 0.9461 - recall: 0.9461 - f1score: 0.9461 - val_loss: 0.0285 - val_acc: 0.9717 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 329/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0530 - acc: 0.9422 - precision: 0.9400 - recall: 0.9400 - f1score: 0.9400 - val_loss: 0.0281 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 330/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0526 - acc: 0.9425 - precision: 0.9456 - recall: 0.9458 - f1score: 0.9457 - val_loss: 0.0271 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 331/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0533 - acc: 0.9416 - precision: 0.9397 - recall: 0.9394 - f1score: 0.9396 - val_loss: 0.0273 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 332/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0532 - acc: 0.9411 - precision: 0.9442 - recall: 0.9442 - f1score: 0.9442 - val_loss: 0.0268 - val_acc: 0.9735 - val_precision: 0.9732 - val_recall: 0.9732 - val_f1score: 0.9732\n",
            "Epoch 333/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0530 - acc: 0.9416 - precision: 0.9392 - recall: 0.9394 - f1score: 0.9393 - val_loss: 0.0275 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 334/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0521 - acc: 0.9434 - precision: 0.9411 - recall: 0.9411 - f1score: 0.9411 - val_loss: 0.0282 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 335/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0526 - acc: 0.9437 - precision: 0.9464 - recall: 0.9467 - f1score: 0.9465 - val_loss: 0.0278 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 336/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0539 - acc: 0.9402 - precision: 0.9378 - recall: 0.9381 - f1score: 0.9379 - val_loss: 0.0278 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 337/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0524 - acc: 0.9425 - precision: 0.9403 - recall: 0.9403 - f1score: 0.9403 - val_loss: 0.0279 - val_acc: 0.9723 - val_precision: 0.9739 - val_recall: 0.9739 - val_f1score: 0.9739\n",
            "Epoch 338/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0530 - acc: 0.9405 - precision: 0.9436 - recall: 0.9439 - f1score: 0.9438 - val_loss: 0.0273 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 339/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0528 - acc: 0.9425 - precision: 0.9350 - recall: 0.9353 - f1score: 0.9351 - val_loss: 0.0288 - val_acc: 0.9717 - val_precision: 0.9721 - val_recall: 0.9721 - val_f1score: 0.9721\n",
            "Epoch 340/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0523 - acc: 0.9422 - precision: 0.9450 - recall: 0.9456 - f1score: 0.9453 - val_loss: 0.0275 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 341/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0523 - acc: 0.9428 - precision: 0.9458 - recall: 0.9458 - f1score: 0.9458 - val_loss: 0.0274 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 342/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0522 - acc: 0.9419 - precision: 0.9452 - recall: 0.9447 - f1score: 0.9450 - val_loss: 0.0279 - val_acc: 0.9723 - val_precision: 0.9739 - val_recall: 0.9739 - val_f1score: 0.9739\n",
            "Epoch 343/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0528 - acc: 0.9425 - precision: 0.9400 - recall: 0.9403 - f1score: 0.9401 - val_loss: 0.0283 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 344/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0524 - acc: 0.9425 - precision: 0.9405 - recall: 0.9400 - f1score: 0.9403 - val_loss: 0.0288 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 345/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0532 - acc: 0.9413 - precision: 0.9447 - recall: 0.9447 - f1score: 0.9447 - val_loss: 0.0277 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 346/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0516 - acc: 0.9443 - precision: 0.9419 - recall: 0.9419 - f1score: 0.9419 - val_loss: 0.0279 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 347/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0521 - acc: 0.9440 - precision: 0.9470 - recall: 0.9472 - f1score: 0.9471 - val_loss: 0.0276 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 348/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0526 - acc: 0.9431 - precision: 0.9408 - recall: 0.9411 - f1score: 0.9410 - val_loss: 0.0280 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 349/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0518 - acc: 0.9434 - precision: 0.9464 - recall: 0.9461 - f1score: 0.9462 - val_loss: 0.0279 - val_acc: 0.9717 - val_precision: 0.9703 - val_recall: 0.9703 - val_f1score: 0.9703\n",
            "Epoch 350/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0531 - acc: 0.9413 - precision: 0.9444 - recall: 0.9444 - f1score: 0.9444 - val_loss: 0.0282 - val_acc: 0.9717 - val_precision: 0.9721 - val_recall: 0.9721 - val_f1score: 0.9721\n",
            "Epoch 351/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0520 - acc: 0.9431 - precision: 0.9461 - recall: 0.9461 - f1score: 0.9461 - val_loss: 0.0280 - val_acc: 0.9717 - val_precision: 0.9709 - val_recall: 0.9709 - val_f1score: 0.9709\n",
            "Epoch 352/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0521 - acc: 0.9419 - precision: 0.9448 - recall: 0.9458 - f1score: 0.9453 - val_loss: 0.0286 - val_acc: 0.9717 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 353/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0519 - acc: 0.9428 - precision: 0.9406 - recall: 0.9406 - f1score: 0.9406 - val_loss: 0.0279 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 354/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0523 - acc: 0.9434 - precision: 0.9356 - recall: 0.9358 - f1score: 0.9357 - val_loss: 0.0286 - val_acc: 0.9717 - val_precision: 0.9721 - val_recall: 0.9721 - val_f1score: 0.9721\n",
            "Epoch 355/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0523 - acc: 0.9428 - precision: 0.9405 - recall: 0.9403 - f1score: 0.9404 - val_loss: 0.0285 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 356/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0521 - acc: 0.9428 - precision: 0.9464 - recall: 0.9458 - f1score: 0.9461 - val_loss: 0.0283 - val_acc: 0.9717 - val_precision: 0.9721 - val_recall: 0.9721 - val_f1score: 0.9721\n",
            "Epoch 357/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0520 - acc: 0.9419 - precision: 0.9400 - recall: 0.9397 - f1score: 0.9398 - val_loss: 0.0280 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 358/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0516 - acc: 0.9440 - precision: 0.9422 - recall: 0.9417 - f1score: 0.9419 - val_loss: 0.0274 - val_acc: 0.9723 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 359/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0513 - acc: 0.9443 - precision: 0.9475 - recall: 0.9475 - f1score: 0.9475 - val_loss: 0.0284 - val_acc: 0.9717 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 360/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0526 - acc: 0.9419 - precision: 0.9450 - recall: 0.9447 - f1score: 0.9449 - val_loss: 0.0283 - val_acc: 0.9711 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 361/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0520 - acc: 0.9434 - precision: 0.9411 - recall: 0.9408 - f1score: 0.9410 - val_loss: 0.0279 - val_acc: 0.9717 - val_precision: 0.9721 - val_recall: 0.9721 - val_f1score: 0.9721\n",
            "Epoch 362/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0515 - acc: 0.9437 - precision: 0.9467 - recall: 0.9467 - f1score: 0.9467 - val_loss: 0.0277 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 363/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0518 - acc: 0.9449 - precision: 0.9475 - recall: 0.9475 - f1score: 0.9475 - val_loss: 0.0281 - val_acc: 0.9717 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 364/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0526 - acc: 0.9428 - precision: 0.9458 - recall: 0.9458 - f1score: 0.9458 - val_loss: 0.0278 - val_acc: 0.9717 - val_precision: 0.9721 - val_recall: 0.9721 - val_f1score: 0.9721\n",
            "Epoch 365/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0522 - acc: 0.9434 - precision: 0.9462 - recall: 0.9469 - f1score: 0.9465 - val_loss: 0.0281 - val_acc: 0.9717 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 366/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0516 - acc: 0.9437 - precision: 0.9467 - recall: 0.9467 - f1score: 0.9467 - val_loss: 0.0279 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 367/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0526 - acc: 0.9419 - precision: 0.9447 - recall: 0.9453 - f1score: 0.9450 - val_loss: 0.0278 - val_acc: 0.9723 - val_precision: 0.9720 - val_recall: 0.9720 - val_f1score: 0.9720\n",
            "Epoch 368/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0512 - acc: 0.9437 - precision: 0.9414 - recall: 0.9414 - f1score: 0.9414 - val_loss: 0.0285 - val_acc: 0.9711 - val_precision: 0.9697 - val_recall: 0.9697 - val_f1score: 0.9697\n",
            "Epoch 369/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0524 - acc: 0.9416 - precision: 0.9397 - recall: 0.9394 - f1score: 0.9396 - val_loss: 0.0296 - val_acc: 0.9705 - val_precision: 0.9692 - val_recall: 0.9692 - val_f1score: 0.9692\n",
            "Epoch 370/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0520 - acc: 0.9434 - precision: 0.9464 - recall: 0.9461 - f1score: 0.9462 - val_loss: 0.0282 - val_acc: 0.9711 - val_precision: 0.9709 - val_recall: 0.9709 - val_f1score: 0.9709\n",
            "Epoch 371/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0513 - acc: 0.9446 - precision: 0.9425 - recall: 0.9422 - f1score: 0.9424 - val_loss: 0.0286 - val_acc: 0.9711 - val_precision: 0.9728 - val_recall: 0.9728 - val_f1score: 0.9728\n",
            "Epoch 372/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0509 - acc: 0.9431 - precision: 0.9356 - recall: 0.9356 - f1score: 0.9356 - val_loss: 0.0295 - val_acc: 0.9705 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 373/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0514 - acc: 0.9428 - precision: 0.9406 - recall: 0.9406 - f1score: 0.9406 - val_loss: 0.0289 - val_acc: 0.9711 - val_precision: 0.9703 - val_recall: 0.9703 - val_f1score: 0.9703\n",
            "Epoch 374/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0509 - acc: 0.9431 - precision: 0.9461 - recall: 0.9461 - f1score: 0.9461 - val_loss: 0.0289 - val_acc: 0.9705 - val_precision: 0.9710 - val_recall: 0.9710 - val_f1score: 0.9710\n",
            "Epoch 375/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0520 - acc: 0.9428 - precision: 0.9458 - recall: 0.9458 - f1score: 0.9458 - val_loss: 0.0278 - val_acc: 0.9723 - val_precision: 0.9733 - val_recall: 0.9733 - val_f1score: 0.9733\n",
            "Epoch 376/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0516 - acc: 0.9431 - precision: 0.9411 - recall: 0.9406 - f1score: 0.9408 - val_loss: 0.0295 - val_acc: 0.9711 - val_precision: 0.9703 - val_recall: 0.9703 - val_f1score: 0.9703\n",
            "Epoch 377/1000\n",
            "3410/3410 [==============================] - 0s 20us/sample - loss: 0.0508 - acc: 0.9452 - precision: 0.9428 - recall: 0.9428 - f1score: 0.9428 - val_loss: 0.0289 - val_acc: 0.9711 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 378/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0515 - acc: 0.9437 - precision: 0.9414 - recall: 0.9414 - f1score: 0.9414 - val_loss: 0.0286 - val_acc: 0.9717 - val_precision: 0.9709 - val_recall: 0.9703 - val_f1score: 0.9706\n",
            "Epoch 379/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0512 - acc: 0.9431 - precision: 0.9461 - recall: 0.9461 - f1score: 0.9461 - val_loss: 0.0275 - val_acc: 0.9723 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1score: 0.9714\n",
            "Epoch 380/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0511 - acc: 0.9443 - precision: 0.9472 - recall: 0.9472 - f1score: 0.9472 - val_loss: 0.0284 - val_acc: 0.9711 - val_precision: 0.9697 - val_recall: 0.9697 - val_f1score: 0.9697\n",
            "Epoch 381/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0507 - acc: 0.9437 - precision: 0.9469 - recall: 0.9467 - f1score: 0.9468 - val_loss: 0.0281 - val_acc: 0.9711 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 382/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0517 - acc: 0.9437 - precision: 0.9356 - recall: 0.9361 - f1score: 0.9359 - val_loss: 0.0290 - val_acc: 0.9711 - val_precision: 0.9703 - val_recall: 0.9703 - val_f1score: 0.9703\n",
            "Epoch 383/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0517 - acc: 0.9434 - precision: 0.9469 - recall: 0.9464 - f1score: 0.9467 - val_loss: 0.0284 - val_acc: 0.9711 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 384/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0516 - acc: 0.9440 - precision: 0.9417 - recall: 0.9417 - f1score: 0.9417 - val_loss: 0.0294 - val_acc: 0.9705 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 385/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0511 - acc: 0.9449 - precision: 0.9480 - recall: 0.9478 - f1score: 0.9479 - val_loss: 0.0284 - val_acc: 0.9711 - val_precision: 0.9703 - val_recall: 0.9703 - val_f1score: 0.9703\n",
            "Epoch 386/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0518 - acc: 0.9425 - precision: 0.9403 - recall: 0.9403 - f1score: 0.9403 - val_loss: 0.0288 - val_acc: 0.9711 - val_precision: 0.9685 - val_recall: 0.9685 - val_f1score: 0.9685\n",
            "Epoch 387/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0505 - acc: 0.9449 - precision: 0.9478 - recall: 0.9481 - f1score: 0.9479 - val_loss: 0.0282 - val_acc: 0.9717 - val_precision: 0.9727 - val_recall: 0.9727 - val_f1score: 0.9727\n",
            "Epoch 388/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0511 - acc: 0.9452 - precision: 0.9478 - recall: 0.9481 - f1score: 0.9479 - val_loss: 0.0283 - val_acc: 0.9717 - val_precision: 0.9696 - val_recall: 0.9696 - val_f1score: 0.9696\n",
            "Epoch 389/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0513 - acc: 0.9422 - precision: 0.9453 - recall: 0.9453 - f1score: 0.9453 - val_loss: 0.0295 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 390/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0508 - acc: 0.9443 - precision: 0.9366 - recall: 0.9361 - f1score: 0.9364 - val_loss: 0.0297 - val_acc: 0.9699 - val_precision: 0.9692 - val_recall: 0.9692 - val_f1score: 0.9692\n",
            "Epoch 391/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0506 - acc: 0.9440 - precision: 0.9419 - recall: 0.9417 - f1score: 0.9418 - val_loss: 0.0291 - val_acc: 0.9705 - val_precision: 0.9716 - val_recall: 0.9716 - val_f1score: 0.9716\n",
            "Epoch 392/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0506 - acc: 0.9443 - precision: 0.9419 - recall: 0.9417 - f1score: 0.9418 - val_loss: 0.0291 - val_acc: 0.9711 - val_precision: 0.9709 - val_recall: 0.9709 - val_f1score: 0.9709\n",
            "Epoch 393/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0514 - acc: 0.9446 - precision: 0.9477 - recall: 0.9469 - f1score: 0.9473 - val_loss: 0.0286 - val_acc: 0.9711 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 394/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0507 - acc: 0.9449 - precision: 0.9480 - recall: 0.9478 - f1score: 0.9479 - val_loss: 0.0282 - val_acc: 0.9717 - val_precision: 0.9703 - val_recall: 0.9703 - val_f1score: 0.9703\n",
            "Epoch 395/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0512 - acc: 0.9443 - precision: 0.9419 - recall: 0.9419 - f1score: 0.9419 - val_loss: 0.0290 - val_acc: 0.9705 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 396/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0512 - acc: 0.9434 - precision: 0.9461 - recall: 0.9464 - f1score: 0.9463 - val_loss: 0.0284 - val_acc: 0.9717 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 397/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0507 - acc: 0.9457 - precision: 0.9489 - recall: 0.9486 - f1score: 0.9487 - val_loss: 0.0280 - val_acc: 0.9711 - val_precision: 0.9709 - val_recall: 0.9709 - val_f1score: 0.9709\n",
            "Epoch 398/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0509 - acc: 0.9428 - precision: 0.9348 - recall: 0.9361 - f1score: 0.9355 - val_loss: 0.0301 - val_acc: 0.9699 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 399/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0512 - acc: 0.9428 - precision: 0.9353 - recall: 0.9356 - f1score: 0.9354 - val_loss: 0.0292 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 400/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0519 - acc: 0.9431 - precision: 0.9461 - recall: 0.9461 - f1score: 0.9461 - val_loss: 0.0287 - val_acc: 0.9711 - val_precision: 0.9722 - val_recall: 0.9722 - val_f1score: 0.9722\n",
            "Epoch 401/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0512 - acc: 0.9443 - precision: 0.9419 - recall: 0.9419 - f1score: 0.9419 - val_loss: 0.0292 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 402/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0510 - acc: 0.9437 - precision: 0.9364 - recall: 0.9361 - f1score: 0.9362 - val_loss: 0.0292 - val_acc: 0.9705 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 403/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0510 - acc: 0.9437 - precision: 0.9416 - recall: 0.9414 - f1score: 0.9415 - val_loss: 0.0291 - val_acc: 0.9711 - val_precision: 0.9709 - val_recall: 0.9709 - val_f1score: 0.9709\n",
            "Epoch 404/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0510 - acc: 0.9422 - precision: 0.9294 - recall: 0.9294 - f1score: 0.9294 - val_loss: 0.0288 - val_acc: 0.9711 - val_precision: 0.9697 - val_recall: 0.9697 - val_f1score: 0.9697\n",
            "Epoch 405/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0515 - acc: 0.9437 - precision: 0.9308 - recall: 0.9306 - f1score: 0.9307 - val_loss: 0.0299 - val_acc: 0.9705 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 406/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0509 - acc: 0.9437 - precision: 0.9361 - recall: 0.9361 - f1score: 0.9361 - val_loss: 0.0290 - val_acc: 0.9705 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 407/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0514 - acc: 0.9434 - precision: 0.9464 - recall: 0.9461 - f1score: 0.9462 - val_loss: 0.0288 - val_acc: 0.9705 - val_precision: 0.9710 - val_recall: 0.9710 - val_f1score: 0.9710\n",
            "Epoch 408/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0501 - acc: 0.9446 - precision: 0.9475 - recall: 0.9475 - f1score: 0.9475 - val_loss: 0.0286 - val_acc: 0.9711 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 409/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0502 - acc: 0.9440 - precision: 0.9422 - recall: 0.9417 - f1score: 0.9419 - val_loss: 0.0291 - val_acc: 0.9705 - val_precision: 0.9716 - val_recall: 0.9716 - val_f1score: 0.9716\n",
            "Epoch 410/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0511 - acc: 0.9446 - precision: 0.9475 - recall: 0.9475 - f1score: 0.9475 - val_loss: 0.0288 - val_acc: 0.9705 - val_precision: 0.9692 - val_recall: 0.9692 - val_f1score: 0.9692\n",
            "Epoch 411/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0498 - acc: 0.9449 - precision: 0.9425 - recall: 0.9422 - f1score: 0.9424 - val_loss: 0.0283 - val_acc: 0.9711 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 412/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0513 - acc: 0.9443 - precision: 0.9472 - recall: 0.9472 - f1score: 0.9472 - val_loss: 0.0290 - val_acc: 0.9705 - val_precision: 0.9716 - val_recall: 0.9716 - val_f1score: 0.9716\n",
            "Epoch 413/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0505 - acc: 0.9455 - precision: 0.9483 - recall: 0.9483 - f1score: 0.9483 - val_loss: 0.0286 - val_acc: 0.9705 - val_precision: 0.9715 - val_recall: 0.9710 - val_f1score: 0.9713\n",
            "Epoch 414/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0505 - acc: 0.9440 - precision: 0.9470 - recall: 0.9472 - f1score: 0.9471 - val_loss: 0.0286 - val_acc: 0.9711 - val_precision: 0.9709 - val_recall: 0.9709 - val_f1score: 0.9709\n",
            "Epoch 415/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0506 - acc: 0.9443 - precision: 0.9422 - recall: 0.9417 - f1score: 0.9419 - val_loss: 0.0297 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 416/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0505 - acc: 0.9431 - precision: 0.9461 - recall: 0.9464 - f1score: 0.9463 - val_loss: 0.0287 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 417/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0512 - acc: 0.9431 - precision: 0.9408 - recall: 0.9408 - f1score: 0.9408 - val_loss: 0.0291 - val_acc: 0.9705 - val_precision: 0.9710 - val_recall: 0.9710 - val_f1score: 0.9710\n",
            "Epoch 418/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0506 - acc: 0.9443 - precision: 0.9472 - recall: 0.9472 - f1score: 0.9472 - val_loss: 0.0295 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 419/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0505 - acc: 0.9443 - precision: 0.9472 - recall: 0.9472 - f1score: 0.9472 - val_loss: 0.0288 - val_acc: 0.9705 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 420/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0508 - acc: 0.9449 - precision: 0.9425 - recall: 0.9422 - f1score: 0.9424 - val_loss: 0.0293 - val_acc: 0.9705 - val_precision: 0.9716 - val_recall: 0.9716 - val_f1score: 0.9716\n",
            "Epoch 421/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0503 - acc: 0.9443 - precision: 0.9472 - recall: 0.9475 - f1score: 0.9474 - val_loss: 0.0290 - val_acc: 0.9699 - val_precision: 0.9686 - val_recall: 0.9686 - val_f1score: 0.9686\n",
            "Epoch 422/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0517 - acc: 0.9422 - precision: 0.9453 - recall: 0.9456 - f1score: 0.9454 - val_loss: 0.0299 - val_acc: 0.9699 - val_precision: 0.9710 - val_recall: 0.9705 - val_f1score: 0.9708\n",
            "Epoch 423/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0505 - acc: 0.9449 - precision: 0.9425 - recall: 0.9425 - f1score: 0.9425 - val_loss: 0.0290 - val_acc: 0.9705 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 424/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0510 - acc: 0.9443 - precision: 0.9419 - recall: 0.9419 - f1score: 0.9419 - val_loss: 0.0293 - val_acc: 0.9705 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 425/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0498 - acc: 0.9457 - precision: 0.9433 - recall: 0.9431 - f1score: 0.9432 - val_loss: 0.0293 - val_acc: 0.9711 - val_precision: 0.9722 - val_recall: 0.9722 - val_f1score: 0.9722\n",
            "Epoch 426/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0498 - acc: 0.9449 - precision: 0.9480 - recall: 0.9481 - f1score: 0.9481 - val_loss: 0.0298 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 427/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0496 - acc: 0.9463 - precision: 0.9492 - recall: 0.9492 - f1score: 0.9492 - val_loss: 0.0289 - val_acc: 0.9705 - val_precision: 0.9692 - val_recall: 0.9692 - val_f1score: 0.9692\n",
            "Epoch 428/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0505 - acc: 0.9457 - precision: 0.9483 - recall: 0.9483 - f1score: 0.9483 - val_loss: 0.0291 - val_acc: 0.9705 - val_precision: 0.9692 - val_recall: 0.9692 - val_f1score: 0.9692\n",
            "Epoch 429/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0507 - acc: 0.9440 - precision: 0.9419 - recall: 0.9417 - f1score: 0.9418 - val_loss: 0.0292 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 430/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0496 - acc: 0.9452 - precision: 0.9481 - recall: 0.9481 - f1score: 0.9481 - val_loss: 0.0288 - val_acc: 0.9711 - val_precision: 0.9722 - val_recall: 0.9722 - val_f1score: 0.9722\n",
            "Epoch 431/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0504 - acc: 0.9452 - precision: 0.9480 - recall: 0.9478 - f1score: 0.9479 - val_loss: 0.0290 - val_acc: 0.9705 - val_precision: 0.9692 - val_recall: 0.9692 - val_f1score: 0.9692\n",
            "Epoch 432/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0497 - acc: 0.9457 - precision: 0.9433 - recall: 0.9433 - f1score: 0.9433 - val_loss: 0.0292 - val_acc: 0.9711 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 433/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0495 - acc: 0.9455 - precision: 0.9483 - recall: 0.9483 - f1score: 0.9483 - val_loss: 0.0293 - val_acc: 0.9705 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 434/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0499 - acc: 0.9455 - precision: 0.9486 - recall: 0.9483 - f1score: 0.9485 - val_loss: 0.0286 - val_acc: 0.9711 - val_precision: 0.9715 - val_recall: 0.9715 - val_f1score: 0.9715\n",
            "Epoch 435/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0504 - acc: 0.9446 - precision: 0.9475 - recall: 0.9472 - f1score: 0.9474 - val_loss: 0.0288 - val_acc: 0.9711 - val_precision: 0.9722 - val_recall: 0.9722 - val_f1score: 0.9722\n",
            "Epoch 436/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0504 - acc: 0.9437 - precision: 0.9467 - recall: 0.9469 - f1score: 0.9468 - val_loss: 0.0291 - val_acc: 0.9705 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 437/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0496 - acc: 0.9455 - precision: 0.9431 - recall: 0.9431 - f1score: 0.9431 - val_loss: 0.0299 - val_acc: 0.9705 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 438/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0502 - acc: 0.9452 - precision: 0.9483 - recall: 0.9481 - f1score: 0.9482 - val_loss: 0.0296 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 439/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0503 - acc: 0.9449 - precision: 0.9267 - recall: 0.9267 - f1score: 0.9267 - val_loss: 0.0311 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 440/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0508 - acc: 0.9440 - precision: 0.9416 - recall: 0.9414 - f1score: 0.9415 - val_loss: 0.0294 - val_acc: 0.9705 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 441/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0505 - acc: 0.9446 - precision: 0.9422 - recall: 0.9422 - f1score: 0.9422 - val_loss: 0.0295 - val_acc: 0.9705 - val_precision: 0.9692 - val_recall: 0.9692 - val_f1score: 0.9692\n",
            "Epoch 442/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0494 - acc: 0.9455 - precision: 0.9431 - recall: 0.9431 - f1score: 0.9431 - val_loss: 0.0296 - val_acc: 0.9705 - val_precision: 0.9685 - val_recall: 0.9680 - val_f1score: 0.9683\n",
            "Epoch 443/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0499 - acc: 0.9449 - precision: 0.9428 - recall: 0.9425 - f1score: 0.9426 - val_loss: 0.0293 - val_acc: 0.9705 - val_precision: 0.9716 - val_recall: 0.9716 - val_f1score: 0.9716\n",
            "Epoch 444/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0495 - acc: 0.9460 - precision: 0.9436 - recall: 0.9433 - f1score: 0.9435 - val_loss: 0.0292 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 445/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0495 - acc: 0.9460 - precision: 0.9489 - recall: 0.9486 - f1score: 0.9487 - val_loss: 0.0298 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 446/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0495 - acc: 0.9455 - precision: 0.9486 - recall: 0.9483 - f1score: 0.9485 - val_loss: 0.0290 - val_acc: 0.9705 - val_precision: 0.9679 - val_recall: 0.9679 - val_f1score: 0.9679\n",
            "Epoch 447/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0496 - acc: 0.9452 - precision: 0.9481 - recall: 0.9483 - f1score: 0.9482 - val_loss: 0.0296 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 448/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0488 - acc: 0.9475 - precision: 0.9447 - recall: 0.9450 - f1score: 0.9449 - val_loss: 0.0302 - val_acc: 0.9693 - val_precision: 0.9692 - val_recall: 0.9687 - val_f1score: 0.9690\n",
            "Epoch 449/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0500 - acc: 0.9457 - precision: 0.9483 - recall: 0.9483 - f1score: 0.9483 - val_loss: 0.0292 - val_acc: 0.9705 - val_precision: 0.9710 - val_recall: 0.9710 - val_f1score: 0.9710\n",
            "Epoch 450/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0504 - acc: 0.9446 - precision: 0.9472 - recall: 0.9475 - f1score: 0.9474 - val_loss: 0.0291 - val_acc: 0.9705 - val_precision: 0.9692 - val_recall: 0.9692 - val_f1score: 0.9692\n",
            "Epoch 451/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0497 - acc: 0.9452 - precision: 0.9478 - recall: 0.9481 - f1score: 0.9479 - val_loss: 0.0291 - val_acc: 0.9705 - val_precision: 0.9710 - val_recall: 0.9710 - val_f1score: 0.9710\n",
            "Epoch 452/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0499 - acc: 0.9452 - precision: 0.9481 - recall: 0.9483 - f1score: 0.9482 - val_loss: 0.0292 - val_acc: 0.9699 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 453/1000\n",
            "3410/3410 [==============================] - ETA: 0s - loss: 0.0839 - acc: 0.9100 - precision: 0.9100 - recall: 0.9100 - f1score: 0.91 - 0s 16us/sample - loss: 0.0501 - acc: 0.9449 - precision: 0.9478 - recall: 0.9478 - f1score: 0.9478 - val_loss: 0.0294 - val_acc: 0.9699 - val_precision: 0.9692 - val_recall: 0.9692 - val_f1score: 0.9692\n",
            "Epoch 454/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0481 - acc: 0.9469 - precision: 0.9495 - recall: 0.9497 - f1score: 0.9496 - val_loss: 0.0301 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 455/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0502 - acc: 0.9449 - precision: 0.9478 - recall: 0.9475 - f1score: 0.9476 - val_loss: 0.0294 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 456/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0500 - acc: 0.9463 - precision: 0.9492 - recall: 0.9492 - f1score: 0.9492 - val_loss: 0.0293 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 457/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0503 - acc: 0.9443 - precision: 0.9473 - recall: 0.9478 - f1score: 0.9475 - val_loss: 0.0295 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 458/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0490 - acc: 0.9469 - precision: 0.9492 - recall: 0.9497 - f1score: 0.9495 - val_loss: 0.0299 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 459/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0495 - acc: 0.9460 - precision: 0.9486 - recall: 0.9489 - f1score: 0.9488 - val_loss: 0.0302 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 460/1000\n",
            "3410/3410 [==============================] - 0s 30us/sample - loss: 0.0495 - acc: 0.9446 - precision: 0.9422 - recall: 0.9422 - f1score: 0.9422 - val_loss: 0.0313 - val_acc: 0.9681 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 461/1000\n",
            "3410/3410 [==============================] - 0s 22us/sample - loss: 0.0497 - acc: 0.9457 - precision: 0.9433 - recall: 0.9431 - f1score: 0.9432 - val_loss: 0.0314 - val_acc: 0.9670 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 462/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0497 - acc: 0.9455 - precision: 0.9483 - recall: 0.9483 - f1score: 0.9483 - val_loss: 0.0302 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 463/1000\n",
            "3410/3410 [==============================] - 0s 21us/sample - loss: 0.0497 - acc: 0.9452 - precision: 0.9481 - recall: 0.9481 - f1score: 0.9481 - val_loss: 0.0296 - val_acc: 0.9699 - val_precision: 0.9692 - val_recall: 0.9692 - val_f1score: 0.9692\n",
            "Epoch 464/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0497 - acc: 0.9460 - precision: 0.9436 - recall: 0.9436 - f1score: 0.9436 - val_loss: 0.0303 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 465/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0490 - acc: 0.9457 - precision: 0.9433 - recall: 0.9433 - f1score: 0.9433 - val_loss: 0.0305 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 466/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0492 - acc: 0.9460 - precision: 0.9434 - recall: 0.9436 - f1score: 0.9435 - val_loss: 0.0306 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 467/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0501 - acc: 0.9460 - precision: 0.9489 - recall: 0.9486 - f1score: 0.9487 - val_loss: 0.0293 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 468/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0500 - acc: 0.9449 - precision: 0.9475 - recall: 0.9475 - f1score: 0.9475 - val_loss: 0.0301 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 469/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0490 - acc: 0.9466 - precision: 0.9494 - recall: 0.9494 - f1score: 0.9494 - val_loss: 0.0297 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 470/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0499 - acc: 0.9457 - precision: 0.9433 - recall: 0.9433 - f1score: 0.9433 - val_loss: 0.0296 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 471/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0503 - acc: 0.9443 - precision: 0.9367 - recall: 0.9369 - f1score: 0.9368 - val_loss: 0.0301 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 472/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0490 - acc: 0.9472 - precision: 0.9500 - recall: 0.9500 - f1score: 0.9500 - val_loss: 0.0299 - val_acc: 0.9705 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 473/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0492 - acc: 0.9452 - precision: 0.9428 - recall: 0.9431 - f1score: 0.9429 - val_loss: 0.0295 - val_acc: 0.9705 - val_precision: 0.9710 - val_recall: 0.9710 - val_f1score: 0.9710\n",
            "Epoch 474/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0490 - acc: 0.9466 - precision: 0.9442 - recall: 0.9442 - f1score: 0.9442 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 475/1000\n",
            "3410/3410 [==============================] - 0s 20us/sample - loss: 0.0487 - acc: 0.9469 - precision: 0.9447 - recall: 0.9497 - f1score: 0.9471 - val_loss: 0.0295 - val_acc: 0.9705 - val_precision: 0.9685 - val_recall: 0.9685 - val_f1score: 0.9685\n",
            "Epoch 476/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0492 - acc: 0.9455 - precision: 0.9433 - recall: 0.9428 - f1score: 0.9430 - val_loss: 0.0306 - val_acc: 0.9687 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 477/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0488 - acc: 0.9463 - precision: 0.9489 - recall: 0.9492 - f1score: 0.9490 - val_loss: 0.0302 - val_acc: 0.9681 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 478/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0495 - acc: 0.9463 - precision: 0.9491 - recall: 0.9489 - f1score: 0.9490 - val_loss: 0.0303 - val_acc: 0.9681 - val_precision: 0.9700 - val_recall: 0.9700 - val_f1score: 0.9700\n",
            "Epoch 479/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0487 - acc: 0.9469 - precision: 0.9444 - recall: 0.9442 - f1score: 0.9443 - val_loss: 0.0299 - val_acc: 0.9687 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 480/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0497 - acc: 0.9460 - precision: 0.9489 - recall: 0.9486 - f1score: 0.9487 - val_loss: 0.0300 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 481/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0484 - acc: 0.9469 - precision: 0.9442 - recall: 0.9444 - f1score: 0.9443 - val_loss: 0.0298 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 482/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0491 - acc: 0.9457 - precision: 0.9486 - recall: 0.9486 - f1score: 0.9486 - val_loss: 0.0298 - val_acc: 0.9699 - val_precision: 0.9686 - val_recall: 0.9686 - val_f1score: 0.9686\n",
            "Epoch 483/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0489 - acc: 0.9466 - precision: 0.9492 - recall: 0.9494 - f1score: 0.9493 - val_loss: 0.0295 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 484/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0485 - acc: 0.9475 - precision: 0.9503 - recall: 0.9503 - f1score: 0.9503 - val_loss: 0.0300 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 485/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0496 - acc: 0.9455 - precision: 0.9483 - recall: 0.9483 - f1score: 0.9483 - val_loss: 0.0303 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 486/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0492 - acc: 0.9457 - precision: 0.9381 - recall: 0.9381 - f1score: 0.9381 - val_loss: 0.0308 - val_acc: 0.9687 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 487/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0490 - acc: 0.9463 - precision: 0.9439 - recall: 0.9439 - f1score: 0.9439 - val_loss: 0.0304 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 488/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0484 - acc: 0.9475 - precision: 0.9450 - recall: 0.9450 - f1score: 0.9450 - val_loss: 0.0316 - val_acc: 0.9681 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 489/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0490 - acc: 0.9469 - precision: 0.9497 - recall: 0.9497 - f1score: 0.9497 - val_loss: 0.0293 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 490/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0484 - acc: 0.9463 - precision: 0.9494 - recall: 0.9489 - f1score: 0.9492 - val_loss: 0.0300 - val_acc: 0.9693 - val_precision: 0.9668 - val_recall: 0.9668 - val_f1score: 0.9668\n",
            "Epoch 491/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0494 - acc: 0.9469 - precision: 0.9444 - recall: 0.9444 - f1score: 0.9444 - val_loss: 0.0304 - val_acc: 0.9699 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 492/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0485 - acc: 0.9469 - precision: 0.9497 - recall: 0.9497 - f1score: 0.9497 - val_loss: 0.0300 - val_acc: 0.9699 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 493/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0496 - acc: 0.9457 - precision: 0.9486 - recall: 0.9486 - f1score: 0.9486 - val_loss: 0.0296 - val_acc: 0.9699 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 494/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0482 - acc: 0.9475 - precision: 0.9450 - recall: 0.9450 - f1score: 0.9450 - val_loss: 0.0310 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 495/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0488 - acc: 0.9457 - precision: 0.9436 - recall: 0.9433 - f1score: 0.9435 - val_loss: 0.0305 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 496/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0482 - acc: 0.9466 - precision: 0.9442 - recall: 0.9442 - f1score: 0.9442 - val_loss: 0.0314 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 497/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0480 - acc: 0.9463 - precision: 0.9386 - recall: 0.9386 - f1score: 0.9386 - val_loss: 0.0317 - val_acc: 0.9676 - val_precision: 0.9676 - val_recall: 0.9676 - val_f1score: 0.9676\n",
            "Epoch 498/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0488 - acc: 0.9472 - precision: 0.9447 - recall: 0.9447 - f1score: 0.9447 - val_loss: 0.0306 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 499/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0488 - acc: 0.9457 - precision: 0.9433 - recall: 0.9433 - f1score: 0.9433 - val_loss: 0.0316 - val_acc: 0.9670 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 500/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0488 - acc: 0.9469 - precision: 0.9497 - recall: 0.9497 - f1score: 0.9497 - val_loss: 0.0307 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 501/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0487 - acc: 0.9472 - precision: 0.9500 - recall: 0.9500 - f1score: 0.9500 - val_loss: 0.0304 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 502/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0485 - acc: 0.9466 - precision: 0.9494 - recall: 0.9492 - f1score: 0.9493 - val_loss: 0.0313 - val_acc: 0.9676 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 503/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0493 - acc: 0.9460 - precision: 0.9489 - recall: 0.9492 - f1score: 0.9490 - val_loss: 0.0298 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 504/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0491 - acc: 0.9463 - precision: 0.9492 - recall: 0.9492 - f1score: 0.9492 - val_loss: 0.0304 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 505/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0484 - acc: 0.9472 - precision: 0.9500 - recall: 0.9500 - f1score: 0.9500 - val_loss: 0.0306 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 506/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0502 - acc: 0.9443 - precision: 0.9472 - recall: 0.9472 - f1score: 0.9472 - val_loss: 0.0300 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 507/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0485 - acc: 0.9487 - precision: 0.9514 - recall: 0.9514 - f1score: 0.9514 - val_loss: 0.0309 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 508/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0481 - acc: 0.9481 - precision: 0.9508 - recall: 0.9508 - f1score: 0.9508 - val_loss: 0.0302 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 509/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0493 - acc: 0.9460 - precision: 0.9433 - recall: 0.9436 - f1score: 0.9435 - val_loss: 0.0315 - val_acc: 0.9681 - val_precision: 0.9700 - val_recall: 0.9700 - val_f1score: 0.9700\n",
            "Epoch 510/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0493 - acc: 0.9460 - precision: 0.9489 - recall: 0.9489 - f1score: 0.9489 - val_loss: 0.0308 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 511/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0493 - acc: 0.9469 - precision: 0.9497 - recall: 0.9497 - f1score: 0.9497 - val_loss: 0.0310 - val_acc: 0.9681 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 512/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0482 - acc: 0.9475 - precision: 0.9503 - recall: 0.9503 - f1score: 0.9503 - val_loss: 0.0314 - val_acc: 0.9670 - val_precision: 0.9664 - val_recall: 0.9664 - val_f1score: 0.9664\n",
            "Epoch 513/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0494 - acc: 0.9463 - precision: 0.9439 - recall: 0.9439 - f1score: 0.9439 - val_loss: 0.0312 - val_acc: 0.9681 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 514/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0486 - acc: 0.9475 - precision: 0.9503 - recall: 0.9500 - f1score: 0.9501 - val_loss: 0.0301 - val_acc: 0.9687 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 515/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0481 - acc: 0.9487 - precision: 0.9514 - recall: 0.9514 - f1score: 0.9514 - val_loss: 0.0313 - val_acc: 0.9681 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 516/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0493 - acc: 0.9455 - precision: 0.9486 - recall: 0.9483 - f1score: 0.9485 - val_loss: 0.0313 - val_acc: 0.9681 - val_precision: 0.9700 - val_recall: 0.9700 - val_f1score: 0.9700\n",
            "Epoch 517/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0485 - acc: 0.9481 - precision: 0.9506 - recall: 0.9506 - f1score: 0.9506 - val_loss: 0.0301 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 518/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0484 - acc: 0.9469 - precision: 0.9497 - recall: 0.9494 - f1score: 0.9496 - val_loss: 0.0315 - val_acc: 0.9681 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 519/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0483 - acc: 0.9475 - precision: 0.9500 - recall: 0.9500 - f1score: 0.9500 - val_loss: 0.0315 - val_acc: 0.9681 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 520/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0495 - acc: 0.9455 - precision: 0.9428 - recall: 0.9433 - f1score: 0.9431 - val_loss: 0.0305 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 521/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0483 - acc: 0.9484 - precision: 0.9458 - recall: 0.9458 - f1score: 0.9458 - val_loss: 0.0309 - val_acc: 0.9687 - val_precision: 0.9706 - val_recall: 0.9706 - val_f1score: 0.9706\n",
            "Epoch 522/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0477 - acc: 0.9490 - precision: 0.9517 - recall: 0.9517 - f1score: 0.9517 - val_loss: 0.0305 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 523/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0491 - acc: 0.9460 - precision: 0.9486 - recall: 0.9489 - f1score: 0.9488 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 524/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0482 - acc: 0.9475 - precision: 0.9450 - recall: 0.9450 - f1score: 0.9450 - val_loss: 0.0318 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 525/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0481 - acc: 0.9466 - precision: 0.9494 - recall: 0.9494 - f1score: 0.9494 - val_loss: 0.0310 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 526/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0483 - acc: 0.9466 - precision: 0.9492 - recall: 0.9497 - f1score: 0.9495 - val_loss: 0.0303 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 527/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0487 - acc: 0.9457 - precision: 0.9483 - recall: 0.9486 - f1score: 0.9485 - val_loss: 0.0314 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 528/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0491 - acc: 0.9466 - precision: 0.9494 - recall: 0.9494 - f1score: 0.9494 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 529/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0482 - acc: 0.9475 - precision: 0.9450 - recall: 0.9447 - f1score: 0.9449 - val_loss: 0.0312 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 530/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0478 - acc: 0.9475 - precision: 0.9397 - recall: 0.9397 - f1score: 0.9397 - val_loss: 0.0320 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 531/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0490 - acc: 0.9469 - precision: 0.9447 - recall: 0.9444 - f1score: 0.9446 - val_loss: 0.0318 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 532/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0482 - acc: 0.9481 - precision: 0.9508 - recall: 0.9508 - f1score: 0.9508 - val_loss: 0.0296 - val_acc: 0.9699 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 533/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0484 - acc: 0.9472 - precision: 0.9500 - recall: 0.9500 - f1score: 0.9500 - val_loss: 0.0308 - val_acc: 0.9687 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 534/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0477 - acc: 0.9475 - precision: 0.9503 - recall: 0.9506 - f1score: 0.9504 - val_loss: 0.0309 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 535/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0486 - acc: 0.9466 - precision: 0.9497 - recall: 0.9494 - f1score: 0.9496 - val_loss: 0.0314 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 536/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0475 - acc: 0.9496 - precision: 0.9469 - recall: 0.9469 - f1score: 0.9469 - val_loss: 0.0314 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 537/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0476 - acc: 0.9487 - precision: 0.9514 - recall: 0.9514 - f1score: 0.9514 - val_loss: 0.0312 - val_acc: 0.9681 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 538/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0488 - acc: 0.9466 - precision: 0.9495 - recall: 0.9497 - f1score: 0.9496 - val_loss: 0.0304 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 539/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0486 - acc: 0.9472 - precision: 0.9450 - recall: 0.9447 - f1score: 0.9449 - val_loss: 0.0309 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 540/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0486 - acc: 0.9466 - precision: 0.9442 - recall: 0.9442 - f1score: 0.9442 - val_loss: 0.0311 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 541/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0475 - acc: 0.9490 - precision: 0.9511 - recall: 0.9517 - f1score: 0.9514 - val_loss: 0.0302 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 542/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0481 - acc: 0.9481 - precision: 0.9511 - recall: 0.9506 - f1score: 0.9508 - val_loss: 0.0309 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 543/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0477 - acc: 0.9475 - precision: 0.9503 - recall: 0.9503 - f1score: 0.9503 - val_loss: 0.0296 - val_acc: 0.9693 - val_precision: 0.9674 - val_recall: 0.9674 - val_f1score: 0.9674\n",
            "Epoch 544/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0488 - acc: 0.9466 - precision: 0.9389 - recall: 0.9389 - f1score: 0.9389 - val_loss: 0.0308 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 545/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0477 - acc: 0.9490 - precision: 0.9516 - recall: 0.9511 - f1score: 0.9514 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 546/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0479 - acc: 0.9478 - precision: 0.9455 - recall: 0.9453 - f1score: 0.9454 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 547/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0476 - acc: 0.9481 - precision: 0.9506 - recall: 0.9508 - f1score: 0.9507 - val_loss: 0.0306 - val_acc: 0.9687 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 548/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0475 - acc: 0.9487 - precision: 0.9514 - recall: 0.9514 - f1score: 0.9514 - val_loss: 0.0307 - val_acc: 0.9687 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 549/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0478 - acc: 0.9469 - precision: 0.9444 - recall: 0.9442 - f1score: 0.9443 - val_loss: 0.0318 - val_acc: 0.9687 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 550/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0480 - acc: 0.9466 - precision: 0.9389 - recall: 0.9394 - f1score: 0.9392 - val_loss: 0.0321 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 551/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0479 - acc: 0.9475 - precision: 0.9447 - recall: 0.9450 - f1score: 0.9449 - val_loss: 0.0319 - val_acc: 0.9681 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 552/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0477 - acc: 0.9472 - precision: 0.9497 - recall: 0.9497 - f1score: 0.9497 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 553/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0480 - acc: 0.9481 - precision: 0.9508 - recall: 0.9508 - f1score: 0.9508 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 554/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0486 - acc: 0.9469 - precision: 0.9444 - recall: 0.9444 - f1score: 0.9444 - val_loss: 0.0306 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 555/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0487 - acc: 0.9478 - precision: 0.9506 - recall: 0.9506 - f1score: 0.9506 - val_loss: 0.0304 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 556/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0480 - acc: 0.9463 - precision: 0.9492 - recall: 0.9492 - f1score: 0.9492 - val_loss: 0.0302 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 557/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0481 - acc: 0.9478 - precision: 0.9505 - recall: 0.9503 - f1score: 0.9504 - val_loss: 0.0306 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 558/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0483 - acc: 0.9475 - precision: 0.9450 - recall: 0.9450 - f1score: 0.9450 - val_loss: 0.0315 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 559/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0473 - acc: 0.9504 - precision: 0.9530 - recall: 0.9528 - f1score: 0.9529 - val_loss: 0.0298 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 560/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0482 - acc: 0.9466 - precision: 0.9494 - recall: 0.9494 - f1score: 0.9494 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9706 - val_recall: 0.9706 - val_f1score: 0.9706\n",
            "Epoch 561/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0467 - acc: 0.9501 - precision: 0.9528 - recall: 0.9528 - f1score: 0.9528 - val_loss: 0.0307 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 562/1000\n",
            "3410/3410 [==============================] - 0s 20us/sample - loss: 0.0485 - acc: 0.9460 - precision: 0.9491 - recall: 0.9489 - f1score: 0.9490 - val_loss: 0.0304 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 563/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0486 - acc: 0.9469 - precision: 0.9442 - recall: 0.9444 - f1score: 0.9443 - val_loss: 0.0302 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 564/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0477 - acc: 0.9490 - precision: 0.9511 - recall: 0.9519 - f1score: 0.9515 - val_loss: 0.0305 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 565/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0470 - acc: 0.9496 - precision: 0.9470 - recall: 0.9472 - f1score: 0.9471 - val_loss: 0.0324 - val_acc: 0.9670 - val_precision: 0.9664 - val_recall: 0.9664 - val_f1score: 0.9664\n",
            "Epoch 566/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0482 - acc: 0.9478 - precision: 0.9455 - recall: 0.9453 - f1score: 0.9454 - val_loss: 0.0316 - val_acc: 0.9687 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 567/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0470 - acc: 0.9493 - precision: 0.9520 - recall: 0.9522 - f1score: 0.9521 - val_loss: 0.0307 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 568/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0474 - acc: 0.9478 - precision: 0.9506 - recall: 0.9508 - f1score: 0.9507 - val_loss: 0.0317 - val_acc: 0.9681 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 569/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0486 - acc: 0.9472 - precision: 0.9394 - recall: 0.9394 - f1score: 0.9394 - val_loss: 0.0315 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 570/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0474 - acc: 0.9487 - precision: 0.9461 - recall: 0.9458 - f1score: 0.9460 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 571/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0471 - acc: 0.9493 - precision: 0.9519 - recall: 0.9519 - f1score: 0.9519 - val_loss: 0.0307 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 572/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0473 - acc: 0.9487 - precision: 0.9514 - recall: 0.9514 - f1score: 0.9514 - val_loss: 0.0306 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 573/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0467 - acc: 0.9487 - precision: 0.9464 - recall: 0.9461 - f1score: 0.9462 - val_loss: 0.0314 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 574/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0482 - acc: 0.9484 - precision: 0.9406 - recall: 0.9406 - f1score: 0.9406 - val_loss: 0.0319 - val_acc: 0.9681 - val_precision: 0.9700 - val_recall: 0.9700 - val_f1score: 0.9700\n",
            "Epoch 575/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0478 - acc: 0.9475 - precision: 0.9503 - recall: 0.9503 - f1score: 0.9503 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 576/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0467 - acc: 0.9493 - precision: 0.9519 - recall: 0.9519 - f1score: 0.9519 - val_loss: 0.0316 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 577/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0478 - acc: 0.9478 - precision: 0.9506 - recall: 0.9506 - f1score: 0.9506 - val_loss: 0.0309 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 578/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0485 - acc: 0.9463 - precision: 0.9492 - recall: 0.9492 - f1score: 0.9492 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 579/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0479 - acc: 0.9487 - precision: 0.9514 - recall: 0.9514 - f1score: 0.9514 - val_loss: 0.0309 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 580/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0480 - acc: 0.9466 - precision: 0.9442 - recall: 0.9442 - f1score: 0.9442 - val_loss: 0.0320 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 581/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0474 - acc: 0.9478 - precision: 0.9400 - recall: 0.9400 - f1score: 0.9400 - val_loss: 0.0325 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 582/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0467 - acc: 0.9496 - precision: 0.9522 - recall: 0.9522 - f1score: 0.9522 - val_loss: 0.0321 - val_acc: 0.9681 - val_precision: 0.9663 - val_recall: 0.9663 - val_f1score: 0.9663\n",
            "Epoch 583/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0469 - acc: 0.9501 - precision: 0.9475 - recall: 0.9475 - f1score: 0.9475 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 584/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0471 - acc: 0.9487 - precision: 0.9514 - recall: 0.9514 - f1score: 0.9514 - val_loss: 0.0306 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 585/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0476 - acc: 0.9481 - precision: 0.9508 - recall: 0.9506 - f1score: 0.9507 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 586/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0474 - acc: 0.9478 - precision: 0.9506 - recall: 0.9506 - f1score: 0.9506 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 587/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0464 - acc: 0.9501 - precision: 0.9475 - recall: 0.9475 - f1score: 0.9475 - val_loss: 0.0311 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 588/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0469 - acc: 0.9487 - precision: 0.9408 - recall: 0.9408 - f1score: 0.9408 - val_loss: 0.0322 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 589/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0470 - acc: 0.9496 - precision: 0.9469 - recall: 0.9469 - f1score: 0.9469 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 590/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0476 - acc: 0.9475 - precision: 0.9503 - recall: 0.9503 - f1score: 0.9503 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 591/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0471 - acc: 0.9484 - precision: 0.9350 - recall: 0.9353 - f1score: 0.9351 - val_loss: 0.0317 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 592/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0462 - acc: 0.9510 - precision: 0.9534 - recall: 0.9536 - f1score: 0.9535 - val_loss: 0.0306 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 593/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0473 - acc: 0.9481 - precision: 0.9508 - recall: 0.9508 - f1score: 0.9508 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 594/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0477 - acc: 0.9478 - precision: 0.9506 - recall: 0.9506 - f1score: 0.9506 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 595/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0478 - acc: 0.9472 - precision: 0.9500 - recall: 0.9500 - f1score: 0.9500 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 596/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0480 - acc: 0.9478 - precision: 0.9503 - recall: 0.9508 - f1score: 0.9506 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 597/1000\n",
            "3410/3410 [==============================] - 0s 20us/sample - loss: 0.0470 - acc: 0.9484 - precision: 0.9511 - recall: 0.9511 - f1score: 0.9511 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 598/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0460 - acc: 0.9504 - precision: 0.9531 - recall: 0.9531 - f1score: 0.9531 - val_loss: 0.0311 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 599/1000\n",
            "3410/3410 [==============================] - 0s 21us/sample - loss: 0.0466 - acc: 0.9493 - precision: 0.9519 - recall: 0.9519 - f1score: 0.9519 - val_loss: 0.0297 - val_acc: 0.9699 - val_precision: 0.9717 - val_recall: 0.9717 - val_f1score: 0.9717\n",
            "Epoch 600/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0462 - acc: 0.9501 - precision: 0.9525 - recall: 0.9528 - f1score: 0.9526 - val_loss: 0.0306 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 601/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0468 - acc: 0.9484 - precision: 0.9511 - recall: 0.9511 - f1score: 0.9511 - val_loss: 0.0306 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 602/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0463 - acc: 0.9493 - precision: 0.9517 - recall: 0.9519 - f1score: 0.9518 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 603/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0465 - acc: 0.9501 - precision: 0.9528 - recall: 0.9528 - f1score: 0.9528 - val_loss: 0.0311 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 604/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0473 - acc: 0.9490 - precision: 0.9464 - recall: 0.9464 - f1score: 0.9464 - val_loss: 0.0317 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 605/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0466 - acc: 0.9496 - precision: 0.9522 - recall: 0.9522 - f1score: 0.9522 - val_loss: 0.0307 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 606/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0473 - acc: 0.9484 - precision: 0.9511 - recall: 0.9511 - f1score: 0.9511 - val_loss: 0.0301 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 607/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0475 - acc: 0.9463 - precision: 0.9491 - recall: 0.9489 - f1score: 0.9490 - val_loss: 0.0312 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 608/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0468 - acc: 0.9487 - precision: 0.9461 - recall: 0.9461 - f1score: 0.9461 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 609/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0475 - acc: 0.9484 - precision: 0.9514 - recall: 0.9511 - f1score: 0.9512 - val_loss: 0.0310 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 610/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0473 - acc: 0.9484 - precision: 0.9511 - recall: 0.9514 - f1score: 0.9513 - val_loss: 0.0310 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 611/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0470 - acc: 0.9499 - precision: 0.9525 - recall: 0.9525 - f1score: 0.9525 - val_loss: 0.0306 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 612/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0478 - acc: 0.9472 - precision: 0.9447 - recall: 0.9447 - f1score: 0.9447 - val_loss: 0.0317 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 613/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0470 - acc: 0.9496 - precision: 0.9520 - recall: 0.9522 - f1score: 0.9521 - val_loss: 0.0307 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 614/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0472 - acc: 0.9490 - precision: 0.9514 - recall: 0.9514 - f1score: 0.9514 - val_loss: 0.0317 - val_acc: 0.9681 - val_precision: 0.9663 - val_recall: 0.9663 - val_f1score: 0.9663\n",
            "Epoch 615/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0469 - acc: 0.9493 - precision: 0.9522 - recall: 0.9519 - f1score: 0.9521 - val_loss: 0.0309 - val_acc: 0.9687 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 616/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0465 - acc: 0.9499 - precision: 0.9472 - recall: 0.9472 - f1score: 0.9472 - val_loss: 0.0311 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 617/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0473 - acc: 0.9481 - precision: 0.9511 - recall: 0.9508 - f1score: 0.9510 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 618/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0466 - acc: 0.9487 - precision: 0.9461 - recall: 0.9461 - f1score: 0.9461 - val_loss: 0.0310 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 619/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0471 - acc: 0.9493 - precision: 0.9520 - recall: 0.9522 - f1score: 0.9521 - val_loss: 0.0310 - val_acc: 0.9687 - val_precision: 0.9656 - val_recall: 0.9656 - val_f1score: 0.9656\n",
            "Epoch 620/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0462 - acc: 0.9504 - precision: 0.9478 - recall: 0.9478 - f1score: 0.9478 - val_loss: 0.0313 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 621/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0460 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0318 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 622/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0461 - acc: 0.9487 - precision: 0.9461 - recall: 0.9461 - f1score: 0.9461 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 623/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0474 - acc: 0.9481 - precision: 0.9509 - recall: 0.9511 - f1score: 0.9510 - val_loss: 0.0301 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 624/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0460 - acc: 0.9501 - precision: 0.9475 - recall: 0.9478 - f1score: 0.9476 - val_loss: 0.0321 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 625/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0467 - acc: 0.9493 - precision: 0.9467 - recall: 0.9467 - f1score: 0.9467 - val_loss: 0.0314 - val_acc: 0.9687 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 626/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0462 - acc: 0.9501 - precision: 0.9530 - recall: 0.9528 - f1score: 0.9529 - val_loss: 0.0307 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 627/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0465 - acc: 0.9501 - precision: 0.9528 - recall: 0.9525 - f1score: 0.9526 - val_loss: 0.0311 - val_acc: 0.9687 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 628/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0474 - acc: 0.9472 - precision: 0.9500 - recall: 0.9500 - f1score: 0.9500 - val_loss: 0.0304 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 629/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0466 - acc: 0.9490 - precision: 0.9464 - recall: 0.9464 - f1score: 0.9464 - val_loss: 0.0313 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 630/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0456 - acc: 0.9504 - precision: 0.9478 - recall: 0.9478 - f1score: 0.9478 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9706 - val_recall: 0.9706 - val_f1score: 0.9706\n",
            "Epoch 631/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0459 - acc: 0.9499 - precision: 0.9472 - recall: 0.9475 - f1score: 0.9474 - val_loss: 0.0315 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 632/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0456 - acc: 0.9513 - precision: 0.9433 - recall: 0.9433 - f1score: 0.9433 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 633/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0461 - acc: 0.9496 - precision: 0.9520 - recall: 0.9522 - f1score: 0.9521 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 634/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0455 - acc: 0.9510 - precision: 0.9483 - recall: 0.9483 - f1score: 0.9483 - val_loss: 0.0314 - val_acc: 0.9687 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 635/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0466 - acc: 0.9490 - precision: 0.9519 - recall: 0.9517 - f1score: 0.9518 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 636/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0456 - acc: 0.9510 - precision: 0.9536 - recall: 0.9539 - f1score: 0.9538 - val_loss: 0.0311 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 637/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0461 - acc: 0.9501 - precision: 0.9528 - recall: 0.9528 - f1score: 0.9528 - val_loss: 0.0319 - val_acc: 0.9676 - val_precision: 0.9676 - val_recall: 0.9676 - val_f1score: 0.9676\n",
            "Epoch 638/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0457 - acc: 0.9501 - precision: 0.9528 - recall: 0.9528 - f1score: 0.9528 - val_loss: 0.0320 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 639/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0464 - acc: 0.9496 - precision: 0.9469 - recall: 0.9469 - f1score: 0.9469 - val_loss: 0.0318 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 640/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0469 - acc: 0.9496 - precision: 0.9522 - recall: 0.9522 - f1score: 0.9522 - val_loss: 0.0309 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 641/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0470 - acc: 0.9493 - precision: 0.9414 - recall: 0.9411 - f1score: 0.9412 - val_loss: 0.0319 - val_acc: 0.9681 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 642/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0458 - acc: 0.9510 - precision: 0.9536 - recall: 0.9539 - f1score: 0.9538 - val_loss: 0.0313 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 643/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0462 - acc: 0.9499 - precision: 0.9475 - recall: 0.9472 - f1score: 0.9474 - val_loss: 0.0315 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 644/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0454 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 645/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0466 - acc: 0.9493 - precision: 0.9466 - recall: 0.9464 - f1score: 0.9465 - val_loss: 0.0317 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 646/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0471 - acc: 0.9481 - precision: 0.9508 - recall: 0.9511 - f1score: 0.9510 - val_loss: 0.0310 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 647/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0466 - acc: 0.9501 - precision: 0.9528 - recall: 0.9528 - f1score: 0.9528 - val_loss: 0.0313 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 648/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0466 - acc: 0.9504 - precision: 0.9528 - recall: 0.9531 - f1score: 0.9529 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 649/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0464 - acc: 0.9496 - precision: 0.9364 - recall: 0.9364 - f1score: 0.9364 - val_loss: 0.0312 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 650/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0469 - acc: 0.9487 - precision: 0.9461 - recall: 0.9461 - f1score: 0.9461 - val_loss: 0.0323 - val_acc: 0.9681 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 651/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0448 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0321 - val_acc: 0.9676 - val_precision: 0.9658 - val_recall: 0.9658 - val_f1score: 0.9658\n",
            "Epoch 652/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0460 - acc: 0.9507 - precision: 0.9536 - recall: 0.9533 - f1score: 0.9535 - val_loss: 0.0310 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 653/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0457 - acc: 0.9510 - precision: 0.9483 - recall: 0.9478 - f1score: 0.9480 - val_loss: 0.0315 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 654/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0453 - acc: 0.9519 - precision: 0.9492 - recall: 0.9492 - f1score: 0.9492 - val_loss: 0.0312 - val_acc: 0.9693 - val_precision: 0.9668 - val_recall: 0.9668 - val_f1score: 0.9668\n",
            "Epoch 655/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0451 - acc: 0.9513 - precision: 0.9486 - recall: 0.9486 - f1score: 0.9486 - val_loss: 0.0312 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 656/1000\n",
            "3410/3410 [==============================] - 0s 23us/sample - loss: 0.0456 - acc: 0.9501 - precision: 0.9528 - recall: 0.9528 - f1score: 0.9528 - val_loss: 0.0319 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 657/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0465 - acc: 0.9493 - precision: 0.9519 - recall: 0.9519 - f1score: 0.9519 - val_loss: 0.0314 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 658/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0457 - acc: 0.9516 - precision: 0.9539 - recall: 0.9542 - f1score: 0.9540 - val_loss: 0.0314 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 659/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0461 - acc: 0.9496 - precision: 0.9525 - recall: 0.9522 - f1score: 0.9524 - val_loss: 0.0314 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 660/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0459 - acc: 0.9507 - precision: 0.9533 - recall: 0.9536 - f1score: 0.9535 - val_loss: 0.0310 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 661/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0462 - acc: 0.9499 - precision: 0.9472 - recall: 0.9472 - f1score: 0.9472 - val_loss: 0.0315 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 662/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0461 - acc: 0.9501 - precision: 0.9530 - recall: 0.9528 - f1score: 0.9529 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 663/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0461 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0307 - val_acc: 0.9693 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 664/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0462 - acc: 0.9493 - precision: 0.9467 - recall: 0.9467 - f1score: 0.9467 - val_loss: 0.0317 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 665/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0450 - acc: 0.9516 - precision: 0.9539 - recall: 0.9542 - f1score: 0.9540 - val_loss: 0.0309 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 666/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0464 - acc: 0.9496 - precision: 0.9525 - recall: 0.9525 - f1score: 0.9525 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 667/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0456 - acc: 0.9510 - precision: 0.9483 - recall: 0.9483 - f1score: 0.9483 - val_loss: 0.0316 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 668/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0456 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 669/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0455 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0321 - val_acc: 0.9681 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 670/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0455 - acc: 0.9507 - precision: 0.9536 - recall: 0.9533 - f1score: 0.9535 - val_loss: 0.0320 - val_acc: 0.9676 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 671/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0456 - acc: 0.9501 - precision: 0.9528 - recall: 0.9528 - f1score: 0.9528 - val_loss: 0.0310 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 672/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0458 - acc: 0.9499 - precision: 0.9472 - recall: 0.9472 - f1score: 0.9472 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 673/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0446 - acc: 0.9516 - precision: 0.9539 - recall: 0.9542 - f1score: 0.9540 - val_loss: 0.0308 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 674/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0457 - acc: 0.9513 - precision: 0.9536 - recall: 0.9539 - f1score: 0.9538 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 675/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0457 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0317 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 676/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0458 - acc: 0.9510 - precision: 0.9483 - recall: 0.9483 - f1score: 0.9483 - val_loss: 0.0320 - val_acc: 0.9676 - val_precision: 0.9664 - val_recall: 0.9664 - val_f1score: 0.9664\n",
            "Epoch 677/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0459 - acc: 0.9501 - precision: 0.9475 - recall: 0.9475 - f1score: 0.9475 - val_loss: 0.0326 - val_acc: 0.9676 - val_precision: 0.9676 - val_recall: 0.9676 - val_f1score: 0.9676\n",
            "Epoch 678/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0464 - acc: 0.9499 - precision: 0.9419 - recall: 0.9419 - f1score: 0.9419 - val_loss: 0.0331 - val_acc: 0.9670 - val_precision: 0.9677 - val_recall: 0.9677 - val_f1score: 0.9677\n",
            "Epoch 679/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0467 - acc: 0.9487 - precision: 0.9514 - recall: 0.9517 - f1score: 0.9515 - val_loss: 0.0314 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 680/1000\n",
            "3410/3410 [==============================] - 0s 23us/sample - loss: 0.0458 - acc: 0.9496 - precision: 0.9522 - recall: 0.9522 - f1score: 0.9522 - val_loss: 0.0311 - val_acc: 0.9699 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 681/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0452 - acc: 0.9516 - precision: 0.9489 - recall: 0.9489 - f1score: 0.9489 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 682/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0456 - acc: 0.9507 - precision: 0.9481 - recall: 0.9481 - f1score: 0.9481 - val_loss: 0.0314 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 683/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0452 - acc: 0.9516 - precision: 0.9436 - recall: 0.9436 - f1score: 0.9436 - val_loss: 0.0323 - val_acc: 0.9681 - val_precision: 0.9700 - val_recall: 0.9700 - val_f1score: 0.9700\n",
            "Epoch 684/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0460 - acc: 0.9504 - precision: 0.9480 - recall: 0.9478 - f1score: 0.9479 - val_loss: 0.0314 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 685/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0456 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0306 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 686/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0455 - acc: 0.9519 - precision: 0.9542 - recall: 0.9544 - f1score: 0.9543 - val_loss: 0.0309 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 687/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0455 - acc: 0.9510 - precision: 0.9533 - recall: 0.9536 - f1score: 0.9535 - val_loss: 0.0315 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 688/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0457 - acc: 0.9504 - precision: 0.9531 - recall: 0.9533 - f1score: 0.9532 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 689/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0452 - acc: 0.9516 - precision: 0.9436 - recall: 0.9436 - f1score: 0.9436 - val_loss: 0.0325 - val_acc: 0.9664 - val_precision: 0.9677 - val_recall: 0.9677 - val_f1score: 0.9677\n",
            "Epoch 690/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0460 - acc: 0.9501 - precision: 0.9528 - recall: 0.9528 - f1score: 0.9528 - val_loss: 0.0311 - val_acc: 0.9699 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 691/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0459 - acc: 0.9507 - precision: 0.9536 - recall: 0.9533 - f1score: 0.9535 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 692/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0449 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0318 - val_acc: 0.9681 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 693/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0456 - acc: 0.9504 - precision: 0.9478 - recall: 0.9478 - f1score: 0.9478 - val_loss: 0.0322 - val_acc: 0.9670 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 694/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0451 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0317 - val_acc: 0.9681 - val_precision: 0.9700 - val_recall: 0.9700 - val_f1score: 0.9700\n",
            "Epoch 695/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0451 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 696/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0449 - acc: 0.9519 - precision: 0.9544 - recall: 0.9542 - f1score: 0.9543 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 697/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0453 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0309 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 698/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0462 - acc: 0.9501 - precision: 0.9472 - recall: 0.9475 - f1score: 0.9474 - val_loss: 0.0318 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 699/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0455 - acc: 0.9507 - precision: 0.9481 - recall: 0.9481 - f1score: 0.9481 - val_loss: 0.0314 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 700/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0466 - acc: 0.9499 - precision: 0.9472 - recall: 0.9472 - f1score: 0.9472 - val_loss: 0.0319 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 701/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0451 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0313 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 702/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0455 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0314 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 703/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0452 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0315 - val_acc: 0.9687 - val_precision: 0.9706 - val_recall: 0.9706 - val_f1score: 0.9706\n",
            "Epoch 704/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0452 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0321 - val_acc: 0.9670 - val_precision: 0.9689 - val_recall: 0.9689 - val_f1score: 0.9689\n",
            "Epoch 705/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0454 - acc: 0.9510 - precision: 0.9483 - recall: 0.9483 - f1score: 0.9483 - val_loss: 0.0321 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 706/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0457 - acc: 0.9490 - precision: 0.9517 - recall: 0.9517 - f1score: 0.9517 - val_loss: 0.0323 - val_acc: 0.9670 - val_precision: 0.9664 - val_recall: 0.9664 - val_f1score: 0.9664\n",
            "Epoch 707/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0450 - acc: 0.9516 - precision: 0.9489 - recall: 0.9489 - f1score: 0.9489 - val_loss: 0.0319 - val_acc: 0.9670 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 708/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0453 - acc: 0.9513 - precision: 0.9486 - recall: 0.9486 - f1score: 0.9486 - val_loss: 0.0345 - val_acc: 0.9622 - val_precision: 0.9638 - val_recall: 0.9638 - val_f1score: 0.9638\n",
            "Epoch 709/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0459 - acc: 0.9501 - precision: 0.9528 - recall: 0.9528 - f1score: 0.9528 - val_loss: 0.0321 - val_acc: 0.9670 - val_precision: 0.9664 - val_recall: 0.9664 - val_f1score: 0.9664\n",
            "Epoch 710/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0451 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0313 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 711/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0453 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0321 - val_acc: 0.9658 - val_precision: 0.9647 - val_recall: 0.9647 - val_f1score: 0.9647\n",
            "Epoch 712/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0459 - acc: 0.9504 - precision: 0.9531 - recall: 0.9531 - f1score: 0.9531 - val_loss: 0.0307 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 713/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0450 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 714/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0444 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0318 - val_acc: 0.9664 - val_precision: 0.9671 - val_recall: 0.9671 - val_f1score: 0.9671\n",
            "Epoch 715/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0456 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0304 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 716/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0457 - acc: 0.9496 - precision: 0.9472 - recall: 0.9469 - f1score: 0.9471 - val_loss: 0.0310 - val_acc: 0.9699 - val_precision: 0.9692 - val_recall: 0.9692 - val_f1score: 0.9692\n",
            "Epoch 717/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0447 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0305 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 718/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0449 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0310 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 719/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0448 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0308 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 720/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0454 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0312 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 721/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0453 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0316 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 722/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0449 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0321 - val_acc: 0.9670 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 723/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0447 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0315 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 724/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0465 - acc: 0.9493 - precision: 0.9467 - recall: 0.9467 - f1score: 0.9467 - val_loss: 0.0320 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 725/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0449 - acc: 0.9519 - precision: 0.9544 - recall: 0.9544 - f1score: 0.9544 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 726/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0444 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0316 - val_acc: 0.9676 - val_precision: 0.9681 - val_recall: 0.9676 - val_f1score: 0.9679\n",
            "Epoch 727/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0456 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0307 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 728/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0453 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 729/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0448 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0308 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 730/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0444 - acc: 0.9531 - precision: 0.9450 - recall: 0.9450 - f1score: 0.9450 - val_loss: 0.0322 - val_acc: 0.9664 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 731/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0457 - acc: 0.9504 - precision: 0.9478 - recall: 0.9478 - f1score: 0.9478 - val_loss: 0.0318 - val_acc: 0.9676 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 732/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0447 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0310 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 733/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0451 - acc: 0.9519 - precision: 0.9544 - recall: 0.9544 - f1score: 0.9544 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 734/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0450 - acc: 0.9513 - precision: 0.9433 - recall: 0.9431 - f1score: 0.9432 - val_loss: 0.0327 - val_acc: 0.9658 - val_precision: 0.9672 - val_recall: 0.9672 - val_f1score: 0.9672\n",
            "Epoch 735/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0455 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0313 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 736/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0454 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0319 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 737/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0453 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 738/1000\n",
            "3410/3410 [==============================] - 0s 23us/sample - loss: 0.0452 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0312 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 739/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0446 - acc: 0.9513 - precision: 0.9539 - recall: 0.9544 - f1score: 0.9542 - val_loss: 0.0320 - val_acc: 0.9664 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 740/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0457 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 741/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0456 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0314 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 742/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0447 - acc: 0.9516 - precision: 0.9541 - recall: 0.9539 - f1score: 0.9540 - val_loss: 0.0305 - val_acc: 0.9693 - val_precision: 0.9674 - val_recall: 0.9674 - val_f1score: 0.9674\n",
            "Epoch 743/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0448 - acc: 0.9516 - precision: 0.9489 - recall: 0.9492 - f1score: 0.9490 - val_loss: 0.0327 - val_acc: 0.9664 - val_precision: 0.9671 - val_recall: 0.9671 - val_f1score: 0.9671\n",
            "Epoch 744/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0446 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0316 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 745/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0446 - acc: 0.9519 - precision: 0.9544 - recall: 0.9544 - f1score: 0.9544 - val_loss: 0.0308 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 746/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0452 - acc: 0.9499 - precision: 0.9525 - recall: 0.9528 - f1score: 0.9526 - val_loss: 0.0309 - val_acc: 0.9687 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 747/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0462 - acc: 0.9499 - precision: 0.9417 - recall: 0.9419 - f1score: 0.9418 - val_loss: 0.0321 - val_acc: 0.9676 - val_precision: 0.9658 - val_recall: 0.9658 - val_f1score: 0.9658\n",
            "Epoch 748/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0458 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0317 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 749/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0441 - acc: 0.9525 - precision: 0.9497 - recall: 0.9497 - f1score: 0.9497 - val_loss: 0.0322 - val_acc: 0.9676 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 750/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0441 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0309 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 751/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0453 - acc: 0.9510 - precision: 0.9539 - recall: 0.9536 - f1score: 0.9537 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 752/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0450 - acc: 0.9504 - precision: 0.9478 - recall: 0.9481 - f1score: 0.9479 - val_loss: 0.0325 - val_acc: 0.9658 - val_precision: 0.9647 - val_recall: 0.9647 - val_f1score: 0.9647\n",
            "Epoch 753/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0452 - acc: 0.9507 - precision: 0.9478 - recall: 0.9481 - f1score: 0.9479 - val_loss: 0.0328 - val_acc: 0.9658 - val_precision: 0.9672 - val_recall: 0.9672 - val_f1score: 0.9672\n",
            "Epoch 754/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0439 - acc: 0.9528 - precision: 0.9553 - recall: 0.9550 - f1score: 0.9551 - val_loss: 0.0310 - val_acc: 0.9687 - val_precision: 0.9663 - val_recall: 0.9663 - val_f1score: 0.9663\n",
            "Epoch 755/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0442 - acc: 0.9516 - precision: 0.9436 - recall: 0.9436 - f1score: 0.9436 - val_loss: 0.0332 - val_acc: 0.9652 - val_precision: 0.9654 - val_recall: 0.9654 - val_f1score: 0.9654\n",
            "Epoch 756/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0450 - acc: 0.9522 - precision: 0.9547 - recall: 0.9550 - f1score: 0.9549 - val_loss: 0.0311 - val_acc: 0.9681 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 757/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0448 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 758/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0449 - acc: 0.9519 - precision: 0.9492 - recall: 0.9492 - f1score: 0.9492 - val_loss: 0.0306 - val_acc: 0.9699 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 759/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0451 - acc: 0.9516 - precision: 0.9489 - recall: 0.9489 - f1score: 0.9489 - val_loss: 0.0324 - val_acc: 0.9658 - val_precision: 0.9659 - val_recall: 0.9659 - val_f1score: 0.9659\n",
            "Epoch 760/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0454 - acc: 0.9504 - precision: 0.9372 - recall: 0.9372 - f1score: 0.9372 - val_loss: 0.0312 - val_acc: 0.9699 - val_precision: 0.9686 - val_recall: 0.9686 - val_f1score: 0.9686\n",
            "Epoch 761/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0444 - acc: 0.9519 - precision: 0.9492 - recall: 0.9492 - f1score: 0.9492 - val_loss: 0.0324 - val_acc: 0.9658 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 762/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0439 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0318 - val_acc: 0.9670 - val_precision: 0.9664 - val_recall: 0.9664 - val_f1score: 0.9664\n",
            "Epoch 763/1000\n",
            "3410/3410 [==============================] - 0s 28us/sample - loss: 0.0450 - acc: 0.9507 - precision: 0.9483 - recall: 0.9481 - f1score: 0.9482 - val_loss: 0.0314 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 764/1000\n",
            "3410/3410 [==============================] - 0s 29us/sample - loss: 0.0457 - acc: 0.9501 - precision: 0.9528 - recall: 0.9528 - f1score: 0.9528 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 765/1000\n",
            "3410/3410 [==============================] - 0s 23us/sample - loss: 0.0438 - acc: 0.9534 - precision: 0.9561 - recall: 0.9558 - f1score: 0.9560 - val_loss: 0.0302 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 766/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0445 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0304 - val_acc: 0.9687 - val_precision: 0.9663 - val_recall: 0.9663 - val_f1score: 0.9663\n",
            "Epoch 767/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0445 - acc: 0.9522 - precision: 0.9545 - recall: 0.9550 - f1score: 0.9547 - val_loss: 0.0309 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 768/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0448 - acc: 0.9525 - precision: 0.9552 - recall: 0.9547 - f1score: 0.9550 - val_loss: 0.0310 - val_acc: 0.9676 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 769/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0442 - acc: 0.9519 - precision: 0.9544 - recall: 0.9544 - f1score: 0.9544 - val_loss: 0.0303 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 770/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0447 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0312 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 771/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0443 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0298 - val_acc: 0.9699 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 772/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0451 - acc: 0.9516 - precision: 0.9542 - recall: 0.9539 - f1score: 0.9540 - val_loss: 0.0303 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 773/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0444 - acc: 0.9519 - precision: 0.9544 - recall: 0.9544 - f1score: 0.9544 - val_loss: 0.0306 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 774/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0437 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0301 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 775/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0444 - acc: 0.9537 - precision: 0.9559 - recall: 0.9561 - f1score: 0.9560 - val_loss: 0.0309 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 776/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0446 - acc: 0.9519 - precision: 0.9544 - recall: 0.9544 - f1score: 0.9544 - val_loss: 0.0327 - val_acc: 0.9646 - val_precision: 0.9642 - val_recall: 0.9642 - val_f1score: 0.9642\n",
            "Epoch 777/1000\n",
            "3410/3410 [==============================] - 0s 21us/sample - loss: 0.0446 - acc: 0.9516 - precision: 0.9489 - recall: 0.9489 - f1score: 0.9489 - val_loss: 0.0313 - val_acc: 0.9676 - val_precision: 0.9664 - val_recall: 0.9664 - val_f1score: 0.9664\n",
            "Epoch 778/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0442 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 779/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0447 - acc: 0.9522 - precision: 0.9494 - recall: 0.9494 - f1score: 0.9494 - val_loss: 0.0311 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 780/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0446 - acc: 0.9519 - precision: 0.9439 - recall: 0.9439 - f1score: 0.9439 - val_loss: 0.0317 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 781/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0452 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0309 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 782/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0442 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0315 - val_acc: 0.9670 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 783/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0441 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0309 - val_acc: 0.9676 - val_precision: 0.9658 - val_recall: 0.9658 - val_f1score: 0.9658\n",
            "Epoch 784/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0446 - acc: 0.9507 - precision: 0.9480 - recall: 0.9478 - f1score: 0.9479 - val_loss: 0.0308 - val_acc: 0.9687 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 785/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0441 - acc: 0.9531 - precision: 0.9503 - recall: 0.9503 - f1score: 0.9503 - val_loss: 0.0323 - val_acc: 0.9664 - val_precision: 0.9659 - val_recall: 0.9659 - val_f1score: 0.9659\n",
            "Epoch 786/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0439 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0318 - val_acc: 0.9676 - val_precision: 0.9676 - val_recall: 0.9676 - val_f1score: 0.9676\n",
            "Epoch 787/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0443 - acc: 0.9525 - precision: 0.9550 - recall: 0.9547 - f1score: 0.9549 - val_loss: 0.0299 - val_acc: 0.9693 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 788/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0450 - acc: 0.9516 - precision: 0.9489 - recall: 0.9489 - f1score: 0.9489 - val_loss: 0.0329 - val_acc: 0.9652 - val_precision: 0.9666 - val_recall: 0.9661 - val_f1score: 0.9663\n",
            "Epoch 789/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0446 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0303 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 790/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0443 - acc: 0.9525 - precision: 0.9497 - recall: 0.9497 - f1score: 0.9497 - val_loss: 0.0309 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 791/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0443 - acc: 0.9516 - precision: 0.9544 - recall: 0.9539 - f1score: 0.9542 - val_loss: 0.0310 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 792/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0455 - acc: 0.9499 - precision: 0.9475 - recall: 0.9472 - f1score: 0.9474 - val_loss: 0.0311 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 793/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0442 - acc: 0.9525 - precision: 0.9495 - recall: 0.9497 - f1score: 0.9496 - val_loss: 0.0319 - val_acc: 0.9664 - val_precision: 0.9646 - val_recall: 0.9646 - val_f1score: 0.9646\n",
            "Epoch 794/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0445 - acc: 0.9519 - precision: 0.9494 - recall: 0.9492 - f1score: 0.9493 - val_loss: 0.0310 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 795/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0441 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0305 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 796/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0447 - acc: 0.9504 - precision: 0.9425 - recall: 0.9428 - f1score: 0.9426 - val_loss: 0.0337 - val_acc: 0.9622 - val_precision: 0.9620 - val_recall: 0.9620 - val_f1score: 0.9620\n",
            "Epoch 797/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0450 - acc: 0.9516 - precision: 0.9489 - recall: 0.9486 - f1score: 0.9487 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 798/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0448 - acc: 0.9513 - precision: 0.9486 - recall: 0.9486 - f1score: 0.9486 - val_loss: 0.0307 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 799/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0453 - acc: 0.9504 - precision: 0.9531 - recall: 0.9531 - f1score: 0.9531 - val_loss: 0.0305 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 800/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0435 - acc: 0.9540 - precision: 0.9406 - recall: 0.9406 - f1score: 0.9406 - val_loss: 0.0320 - val_acc: 0.9658 - val_precision: 0.9672 - val_recall: 0.9672 - val_f1score: 0.9672\n",
            "Epoch 801/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0440 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0314 - val_acc: 0.9681 - val_precision: 0.9657 - val_recall: 0.9657 - val_f1score: 0.9657\n",
            "Epoch 802/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0446 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 803/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0454 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0312 - val_acc: 0.9670 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 804/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0444 - acc: 0.9522 - precision: 0.9494 - recall: 0.9494 - f1score: 0.9494 - val_loss: 0.0312 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 805/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0449 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0305 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 806/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0446 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0329 - val_acc: 0.9646 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1score: 0.9661\n",
            "Epoch 807/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0446 - acc: 0.9513 - precision: 0.9486 - recall: 0.9486 - f1score: 0.9486 - val_loss: 0.0315 - val_acc: 0.9676 - val_precision: 0.9658 - val_recall: 0.9658 - val_f1score: 0.9658\n",
            "Epoch 808/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0437 - acc: 0.9519 - precision: 0.9544 - recall: 0.9544 - f1score: 0.9544 - val_loss: 0.0307 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 809/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0448 - acc: 0.9522 - precision: 0.9389 - recall: 0.9389 - f1score: 0.9389 - val_loss: 0.0315 - val_acc: 0.9676 - val_precision: 0.9664 - val_recall: 0.9664 - val_f1score: 0.9664\n",
            "Epoch 810/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0440 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0307 - val_acc: 0.9687 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 811/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0454 - acc: 0.9504 - precision: 0.9478 - recall: 0.9478 - f1score: 0.9478 - val_loss: 0.0314 - val_acc: 0.9681 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 812/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0438 - acc: 0.9531 - precision: 0.9556 - recall: 0.9556 - f1score: 0.9556 - val_loss: 0.0305 - val_acc: 0.9705 - val_precision: 0.9710 - val_recall: 0.9710 - val_f1score: 0.9710\n",
            "Epoch 813/1000\n",
            "3410/3410 [==============================] - 0s 22us/sample - loss: 0.0440 - acc: 0.9534 - precision: 0.9558 - recall: 0.9561 - f1score: 0.9560 - val_loss: 0.0311 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 814/1000\n",
            "3410/3410 [==============================] - 0s 38us/sample - loss: 0.0447 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0312 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 815/1000\n",
            "3410/3410 [==============================] - 0s 42us/sample - loss: 0.0436 - acc: 0.9522 - precision: 0.9547 - recall: 0.9550 - f1score: 0.9549 - val_loss: 0.0309 - val_acc: 0.9681 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 816/1000\n",
            "3410/3410 [==============================] - 0s 30us/sample - loss: 0.0451 - acc: 0.9504 - precision: 0.9528 - recall: 0.9533 - f1score: 0.9531 - val_loss: 0.0306 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 817/1000\n",
            "3410/3410 [==============================] - 0s 28us/sample - loss: 0.0442 - acc: 0.9528 - precision: 0.9500 - recall: 0.9500 - f1score: 0.9500 - val_loss: 0.0307 - val_acc: 0.9693 - val_precision: 0.9705 - val_recall: 0.9705 - val_f1score: 0.9705\n",
            "Epoch 818/1000\n",
            "3410/3410 [==============================] - 0s 23us/sample - loss: 0.0445 - acc: 0.9522 - precision: 0.9494 - recall: 0.9494 - f1score: 0.9494 - val_loss: 0.0314 - val_acc: 0.9681 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 819/1000\n",
            "3410/3410 [==============================] - 0s 23us/sample - loss: 0.0445 - acc: 0.9510 - precision: 0.9536 - recall: 0.9536 - f1score: 0.9536 - val_loss: 0.0322 - val_acc: 0.9658 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 820/1000\n",
            "3410/3410 [==============================] - 0s 20us/sample - loss: 0.0452 - acc: 0.9516 - precision: 0.9544 - recall: 0.9542 - f1score: 0.9543 - val_loss: 0.0317 - val_acc: 0.9658 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 821/1000\n",
            "3410/3410 [==============================] - 0s 24us/sample - loss: 0.0446 - acc: 0.9528 - precision: 0.9555 - recall: 0.9553 - f1score: 0.9554 - val_loss: 0.0316 - val_acc: 0.9664 - val_precision: 0.9671 - val_recall: 0.9671 - val_f1score: 0.9671\n",
            "Epoch 822/1000\n",
            "3410/3410 [==============================] - 0s 22us/sample - loss: 0.0439 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0310 - val_acc: 0.9687 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 823/1000\n",
            "3410/3410 [==============================] - 0s 20us/sample - loss: 0.0443 - acc: 0.9519 - precision: 0.9439 - recall: 0.9439 - f1score: 0.9439 - val_loss: 0.0319 - val_acc: 0.9658 - val_precision: 0.9653 - val_recall: 0.9653 - val_f1score: 0.9653\n",
            "Epoch 824/1000\n",
            "3410/3410 [==============================] - 0s 26us/sample - loss: 0.0440 - acc: 0.9519 - precision: 0.9439 - recall: 0.9439 - f1score: 0.9439 - val_loss: 0.0333 - val_acc: 0.9634 - val_precision: 0.9631 - val_recall: 0.9631 - val_f1score: 0.9631\n",
            "Epoch 825/1000\n",
            "3410/3410 [==============================] - 0s 24us/sample - loss: 0.0444 - acc: 0.9519 - precision: 0.9544 - recall: 0.9544 - f1score: 0.9544 - val_loss: 0.0319 - val_acc: 0.9652 - val_precision: 0.9642 - val_recall: 0.9642 - val_f1score: 0.9642\n",
            "Epoch 826/1000\n",
            "3410/3410 [==============================] - 0s 23us/sample - loss: 0.0444 - acc: 0.9525 - precision: 0.9497 - recall: 0.9492 - f1score: 0.9494 - val_loss: 0.0328 - val_acc: 0.9658 - val_precision: 0.9641 - val_recall: 0.9641 - val_f1score: 0.9641\n",
            "Epoch 827/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0444 - acc: 0.9519 - precision: 0.9544 - recall: 0.9544 - f1score: 0.9544 - val_loss: 0.0309 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 828/1000\n",
            "3410/3410 [==============================] - 0s 21us/sample - loss: 0.0445 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0314 - val_acc: 0.9681 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 829/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0449 - acc: 0.9513 - precision: 0.9433 - recall: 0.9433 - f1score: 0.9433 - val_loss: 0.0330 - val_acc: 0.9640 - val_precision: 0.9649 - val_recall: 0.9649 - val_f1score: 0.9649\n",
            "Epoch 830/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0451 - acc: 0.9519 - precision: 0.9491 - recall: 0.9489 - f1score: 0.9490 - val_loss: 0.0316 - val_acc: 0.9681 - val_precision: 0.9663 - val_recall: 0.9663 - val_f1score: 0.9663\n",
            "Epoch 831/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0451 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0304 - val_acc: 0.9705 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 832/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0447 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0305 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 833/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0452 - acc: 0.9507 - precision: 0.9533 - recall: 0.9533 - f1score: 0.9533 - val_loss: 0.0311 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 834/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0443 - acc: 0.9522 - precision: 0.9442 - recall: 0.9442 - f1score: 0.9442 - val_loss: 0.0317 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 835/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0442 - acc: 0.9531 - precision: 0.9556 - recall: 0.9556 - f1score: 0.9556 - val_loss: 0.0314 - val_acc: 0.9681 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 836/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0444 - acc: 0.9516 - precision: 0.9489 - recall: 0.9489 - f1score: 0.9489 - val_loss: 0.0324 - val_acc: 0.9658 - val_precision: 0.9653 - val_recall: 0.9653 - val_f1score: 0.9653\n",
            "Epoch 837/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0439 - acc: 0.9525 - precision: 0.9497 - recall: 0.9497 - f1score: 0.9497 - val_loss: 0.0310 - val_acc: 0.9705 - val_precision: 0.9722 - val_recall: 0.9722 - val_f1score: 0.9722\n",
            "Epoch 838/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0434 - acc: 0.9531 - precision: 0.9556 - recall: 0.9556 - f1score: 0.9556 - val_loss: 0.0311 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 839/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0435 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0305 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 840/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0443 - acc: 0.9507 - precision: 0.9428 - recall: 0.9428 - f1score: 0.9428 - val_loss: 0.0313 - val_acc: 0.9676 - val_precision: 0.9651 - val_recall: 0.9651 - val_f1score: 0.9651\n",
            "Epoch 841/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0440 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0312 - val_acc: 0.9681 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 842/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0438 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0332 - val_acc: 0.9628 - val_precision: 0.9638 - val_recall: 0.9638 - val_f1score: 0.9638\n",
            "Epoch 843/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0439 - acc: 0.9531 - precision: 0.9556 - recall: 0.9556 - f1score: 0.9556 - val_loss: 0.0309 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 844/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0446 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0305 - val_acc: 0.9699 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 845/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0446 - acc: 0.9519 - precision: 0.9492 - recall: 0.9492 - f1score: 0.9492 - val_loss: 0.0320 - val_acc: 0.9658 - val_precision: 0.9672 - val_recall: 0.9672 - val_f1score: 0.9672\n",
            "Epoch 846/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0443 - acc: 0.9525 - precision: 0.9550 - recall: 0.9547 - f1score: 0.9549 - val_loss: 0.0307 - val_acc: 0.9676 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 847/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0442 - acc: 0.9525 - precision: 0.9553 - recall: 0.9550 - f1score: 0.9551 - val_loss: 0.0306 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 848/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0444 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0305 - val_acc: 0.9699 - val_precision: 0.9704 - val_recall: 0.9704 - val_f1score: 0.9704\n",
            "Epoch 849/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0439 - acc: 0.9531 - precision: 0.9558 - recall: 0.9556 - f1score: 0.9557 - val_loss: 0.0311 - val_acc: 0.9676 - val_precision: 0.9676 - val_recall: 0.9676 - val_f1score: 0.9676\n",
            "Epoch 850/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0439 - acc: 0.9534 - precision: 0.9506 - recall: 0.9506 - f1score: 0.9506 - val_loss: 0.0311 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 851/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0431 - acc: 0.9531 - precision: 0.9556 - recall: 0.9556 - f1score: 0.9556 - val_loss: 0.0306 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 852/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0439 - acc: 0.9537 - precision: 0.9561 - recall: 0.9558 - f1score: 0.9560 - val_loss: 0.0317 - val_acc: 0.9670 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1score: 0.9683\n",
            "Epoch 853/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0445 - acc: 0.9519 - precision: 0.9544 - recall: 0.9542 - f1score: 0.9543 - val_loss: 0.0304 - val_acc: 0.9687 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 854/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0434 - acc: 0.9531 - precision: 0.9503 - recall: 0.9503 - f1score: 0.9503 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 855/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0447 - acc: 0.9519 - precision: 0.9544 - recall: 0.9544 - f1score: 0.9544 - val_loss: 0.0303 - val_acc: 0.9699 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1score: 0.9698\n",
            "Epoch 856/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0437 - acc: 0.9528 - precision: 0.9500 - recall: 0.9500 - f1score: 0.9500 - val_loss: 0.0308 - val_acc: 0.9693 - val_precision: 0.9699 - val_recall: 0.9699 - val_f1score: 0.9699\n",
            "Epoch 857/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0448 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0316 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 858/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0439 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0309 - val_acc: 0.9681 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 859/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0444 - acc: 0.9513 - precision: 0.9486 - recall: 0.9486 - f1score: 0.9486 - val_loss: 0.0310 - val_acc: 0.9693 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1score: 0.9680\n",
            "Epoch 860/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0443 - acc: 0.9525 - precision: 0.9444 - recall: 0.9444 - f1score: 0.9444 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 861/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0450 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0307 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 862/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0440 - acc: 0.9528 - precision: 0.9550 - recall: 0.9553 - f1score: 0.9551 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 863/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0438 - acc: 0.9528 - precision: 0.9500 - recall: 0.9500 - f1score: 0.9500 - val_loss: 0.0320 - val_acc: 0.9676 - val_precision: 0.9676 - val_recall: 0.9676 - val_f1score: 0.9676\n",
            "Epoch 864/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0444 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0312 - val_acc: 0.9676 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 865/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0437 - acc: 0.9537 - precision: 0.9456 - recall: 0.9456 - f1score: 0.9456 - val_loss: 0.0324 - val_acc: 0.9664 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 866/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0445 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0309 - val_acc: 0.9676 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 867/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0441 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0308 - val_acc: 0.9676 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 868/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0432 - acc: 0.9531 - precision: 0.9553 - recall: 0.9556 - f1score: 0.9554 - val_loss: 0.0310 - val_acc: 0.9676 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 869/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0439 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0301 - val_acc: 0.9693 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 870/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0441 - acc: 0.9519 - precision: 0.9489 - recall: 0.9492 - f1score: 0.9490 - val_loss: 0.0313 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 871/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0446 - acc: 0.9516 - precision: 0.9489 - recall: 0.9489 - f1score: 0.9489 - val_loss: 0.0312 - val_acc: 0.9670 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 872/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0446 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0309 - val_acc: 0.9676 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 873/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0437 - acc: 0.9531 - precision: 0.9553 - recall: 0.9556 - f1score: 0.9554 - val_loss: 0.0306 - val_acc: 0.9676 - val_precision: 0.9651 - val_recall: 0.9651 - val_f1score: 0.9651\n",
            "Epoch 874/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0453 - acc: 0.9507 - precision: 0.9481 - recall: 0.9481 - f1score: 0.9481 - val_loss: 0.0309 - val_acc: 0.9681 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 875/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0436 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0308 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 876/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0438 - acc: 0.9528 - precision: 0.9500 - recall: 0.9500 - f1score: 0.9500 - val_loss: 0.0331 - val_acc: 0.9652 - val_precision: 0.9635 - val_recall: 0.9635 - val_f1score: 0.9635\n",
            "Epoch 877/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0432 - acc: 0.9537 - precision: 0.9564 - recall: 0.9561 - f1score: 0.9562 - val_loss: 0.0311 - val_acc: 0.9681 - val_precision: 0.9669 - val_recall: 0.9669 - val_f1score: 0.9669\n",
            "Epoch 878/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0438 - acc: 0.9537 - precision: 0.9561 - recall: 0.9561 - f1score: 0.9561 - val_loss: 0.0312 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 879/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0448 - acc: 0.9516 - precision: 0.9491 - recall: 0.9486 - f1score: 0.9489 - val_loss: 0.0317 - val_acc: 0.9676 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 880/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0436 - acc: 0.9531 - precision: 0.9561 - recall: 0.9556 - f1score: 0.9558 - val_loss: 0.0306 - val_acc: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 881/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0434 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0310 - val_acc: 0.9670 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 882/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0442 - acc: 0.9528 - precision: 0.9447 - recall: 0.9447 - f1score: 0.9447 - val_loss: 0.0322 - val_acc: 0.9658 - val_precision: 0.9659 - val_recall: 0.9659 - val_f1score: 0.9659\n",
            "Epoch 883/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0434 - acc: 0.9531 - precision: 0.9503 - recall: 0.9503 - f1score: 0.9503 - val_loss: 0.0333 - val_acc: 0.9652 - val_precision: 0.9660 - val_recall: 0.9660 - val_f1score: 0.9660\n",
            "Epoch 884/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0444 - acc: 0.9522 - precision: 0.9494 - recall: 0.9494 - f1score: 0.9494 - val_loss: 0.0322 - val_acc: 0.9664 - val_precision: 0.9677 - val_recall: 0.9677 - val_f1score: 0.9677\n",
            "Epoch 885/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0435 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0308 - val_acc: 0.9681 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 886/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0438 - acc: 0.9525 - precision: 0.9444 - recall: 0.9444 - f1score: 0.9444 - val_loss: 0.0321 - val_acc: 0.9658 - val_precision: 0.9659 - val_recall: 0.9659 - val_f1score: 0.9659\n",
            "Epoch 887/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0436 - acc: 0.9516 - precision: 0.9544 - recall: 0.9542 - f1score: 0.9543 - val_loss: 0.0314 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 888/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0435 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0317 - val_acc: 0.9664 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 889/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0436 - acc: 0.9525 - precision: 0.9547 - recall: 0.9550 - f1score: 0.9549 - val_loss: 0.0314 - val_acc: 0.9664 - val_precision: 0.9671 - val_recall: 0.9671 - val_f1score: 0.9671\n",
            "Epoch 890/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0438 - acc: 0.9522 - precision: 0.9547 - recall: 0.9544 - f1score: 0.9546 - val_loss: 0.0308 - val_acc: 0.9687 - val_precision: 0.9693 - val_recall: 0.9693 - val_f1score: 0.9693\n",
            "Epoch 891/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0443 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0315 - val_acc: 0.9670 - val_precision: 0.9658 - val_recall: 0.9658 - val_f1score: 0.9658\n",
            "Epoch 892/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0428 - acc: 0.9545 - precision: 0.9567 - recall: 0.9569 - f1score: 0.9568 - val_loss: 0.0319 - val_acc: 0.9664 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 893/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0438 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0315 - val_acc: 0.9676 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 894/1000\n",
            "3410/3410 [==============================] - 0s 20us/sample - loss: 0.0441 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0310 - val_acc: 0.9670 - val_precision: 0.9677 - val_recall: 0.9677 - val_f1score: 0.9677\n",
            "Epoch 895/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0439 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0320 - val_acc: 0.9652 - val_precision: 0.9648 - val_recall: 0.9648 - val_f1score: 0.9648\n",
            "Epoch 896/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0430 - acc: 0.9548 - precision: 0.9519 - recall: 0.9519 - f1score: 0.9519 - val_loss: 0.0320 - val_acc: 0.9658 - val_precision: 0.9647 - val_recall: 0.9647 - val_f1score: 0.9647\n",
            "Epoch 897/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0437 - acc: 0.9537 - precision: 0.9558 - recall: 0.9561 - f1score: 0.9560 - val_loss: 0.0322 - val_acc: 0.9670 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 898/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0437 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0317 - val_acc: 0.9664 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 899/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0443 - acc: 0.9516 - precision: 0.9542 - recall: 0.9542 - f1score: 0.9542 - val_loss: 0.0310 - val_acc: 0.9681 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 900/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0439 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0314 - val_acc: 0.9676 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 901/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0431 - acc: 0.9537 - precision: 0.9350 - recall: 0.9350 - f1score: 0.9350 - val_loss: 0.0341 - val_acc: 0.9646 - val_precision: 0.9648 - val_recall: 0.9648 - val_f1score: 0.9648\n",
            "Epoch 902/1000\n",
            "3410/3410 [==============================] - ETA: 0s - loss: 0.0433 - acc: 0.9538 - precision: 0.9538 - recall: 0.9538 - f1score: 0.95 - 0s 21us/sample - loss: 0.0434 - acc: 0.9537 - precision: 0.9508 - recall: 0.9508 - f1score: 0.9508 - val_loss: 0.0326 - val_acc: 0.9670 - val_precision: 0.9677 - val_recall: 0.9677 - val_f1score: 0.9677\n",
            "Epoch 903/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0441 - acc: 0.9540 - precision: 0.9564 - recall: 0.9564 - f1score: 0.9564 - val_loss: 0.0330 - val_acc: 0.9664 - val_precision: 0.9653 - val_recall: 0.9653 - val_f1score: 0.9653\n",
            "Epoch 904/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0441 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0315 - val_acc: 0.9676 - val_precision: 0.9676 - val_recall: 0.9676 - val_f1score: 0.9676\n",
            "Epoch 905/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0441 - acc: 0.9531 - precision: 0.9505 - recall: 0.9503 - f1score: 0.9504 - val_loss: 0.0311 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 906/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0442 - acc: 0.9513 - precision: 0.9539 - recall: 0.9539 - f1score: 0.9539 - val_loss: 0.0315 - val_acc: 0.9681 - val_precision: 0.9669 - val_recall: 0.9664 - val_f1score: 0.9666\n",
            "Epoch 907/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0434 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0317 - val_acc: 0.9676 - val_precision: 0.9682 - val_recall: 0.9682 - val_f1score: 0.9682\n",
            "Epoch 908/1000\n",
            "3410/3410 [==============================] - ETA: 0s - loss: 0.0265 - acc: 0.9700 - precision: 0.9700 - recall: 0.9700 - f1score: 0.97 - 0s 16us/sample - loss: 0.0431 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 909/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0438 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0313 - val_acc: 0.9681 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 910/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0443 - acc: 0.9525 - precision: 0.9497 - recall: 0.9497 - f1score: 0.9497 - val_loss: 0.0322 - val_acc: 0.9676 - val_precision: 0.9676 - val_recall: 0.9676 - val_f1score: 0.9676\n",
            "Epoch 911/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0441 - acc: 0.9522 - precision: 0.9547 - recall: 0.9550 - f1score: 0.9549 - val_loss: 0.0317 - val_acc: 0.9676 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 912/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0439 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0317 - val_acc: 0.9676 - val_precision: 0.9664 - val_recall: 0.9664 - val_f1score: 0.9664\n",
            "Epoch 913/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0437 - acc: 0.9540 - precision: 0.9511 - recall: 0.9511 - f1score: 0.9511 - val_loss: 0.0323 - val_acc: 0.9670 - val_precision: 0.9689 - val_recall: 0.9689 - val_f1score: 0.9689\n",
            "Epoch 914/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0436 - acc: 0.9525 - precision: 0.9550 - recall: 0.9547 - f1score: 0.9549 - val_loss: 0.0312 - val_acc: 0.9681 - val_precision: 0.9700 - val_recall: 0.9700 - val_f1score: 0.9700\n",
            "Epoch 915/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0433 - acc: 0.9534 - precision: 0.9503 - recall: 0.9506 - f1score: 0.9504 - val_loss: 0.0318 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 916/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0425 - acc: 0.9537 - precision: 0.9511 - recall: 0.9508 - f1score: 0.9510 - val_loss: 0.0325 - val_acc: 0.9658 - val_precision: 0.9623 - val_recall: 0.9623 - val_f1score: 0.9623\n",
            "Epoch 917/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0437 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0322 - val_acc: 0.9658 - val_precision: 0.9641 - val_recall: 0.9641 - val_f1score: 0.9641\n",
            "Epoch 918/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0427 - acc: 0.9548 - precision: 0.9467 - recall: 0.9467 - f1score: 0.9467 - val_loss: 0.0327 - val_acc: 0.9658 - val_precision: 0.9659 - val_recall: 0.9659 - val_f1score: 0.9659\n",
            "Epoch 919/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0441 - acc: 0.9519 - precision: 0.9492 - recall: 0.9492 - f1score: 0.9492 - val_loss: 0.0336 - val_acc: 0.9628 - val_precision: 0.9625 - val_recall: 0.9625 - val_f1score: 0.9625\n",
            "Epoch 920/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0435 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1score: 0.9687\n",
            "Epoch 921/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0437 - acc: 0.9528 - precision: 0.9447 - recall: 0.9447 - f1score: 0.9447 - val_loss: 0.0332 - val_acc: 0.9658 - val_precision: 0.9653 - val_recall: 0.9653 - val_f1score: 0.9653\n",
            "Epoch 922/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0433 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0318 - val_acc: 0.9681 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 923/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0431 - acc: 0.9543 - precision: 0.9461 - recall: 0.9461 - f1score: 0.9461 - val_loss: 0.0315 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 924/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0424 - acc: 0.9543 - precision: 0.9569 - recall: 0.9567 - f1score: 0.9568 - val_loss: 0.0325 - val_acc: 0.9664 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 925/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0432 - acc: 0.9534 - precision: 0.9558 - recall: 0.9561 - f1score: 0.9560 - val_loss: 0.0328 - val_acc: 0.9658 - val_precision: 0.9672 - val_recall: 0.9672 - val_f1score: 0.9672\n",
            "Epoch 926/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0438 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 927/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0438 - acc: 0.9522 - precision: 0.9547 - recall: 0.9547 - f1score: 0.9547 - val_loss: 0.0318 - val_acc: 0.9681 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 928/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0435 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0315 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 929/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0427 - acc: 0.9548 - precision: 0.9572 - recall: 0.9572 - f1score: 0.9572 - val_loss: 0.0312 - val_acc: 0.9687 - val_precision: 0.9681 - val_recall: 0.9681 - val_f1score: 0.9681\n",
            "Epoch 930/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0429 - acc: 0.9540 - precision: 0.9564 - recall: 0.9564 - f1score: 0.9564 - val_loss: 0.0317 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 931/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0438 - acc: 0.9525 - precision: 0.9497 - recall: 0.9497 - f1score: 0.9497 - val_loss: 0.0336 - val_acc: 0.9646 - val_precision: 0.9654 - val_recall: 0.9654 - val_f1score: 0.9654\n",
            "Epoch 932/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0429 - acc: 0.9548 - precision: 0.9572 - recall: 0.9572 - f1score: 0.9572 - val_loss: 0.0321 - val_acc: 0.9664 - val_precision: 0.9677 - val_recall: 0.9677 - val_f1score: 0.9677\n",
            "Epoch 933/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0432 - acc: 0.9534 - precision: 0.9506 - recall: 0.9508 - f1score: 0.9507 - val_loss: 0.0319 - val_acc: 0.9676 - val_precision: 0.9688 - val_recall: 0.9688 - val_f1score: 0.9688\n",
            "Epoch 934/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0429 - acc: 0.9540 - precision: 0.9564 - recall: 0.9564 - f1score: 0.9564 - val_loss: 0.0325 - val_acc: 0.9652 - val_precision: 0.9648 - val_recall: 0.9648 - val_f1score: 0.9648\n",
            "Epoch 935/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0433 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0320 - val_acc: 0.9670 - val_precision: 0.9658 - val_recall: 0.9658 - val_f1score: 0.9658\n",
            "Epoch 936/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0439 - acc: 0.9525 - precision: 0.9550 - recall: 0.9550 - f1score: 0.9550 - val_loss: 0.0324 - val_acc: 0.9658 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 937/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0430 - acc: 0.9543 - precision: 0.9567 - recall: 0.9567 - f1score: 0.9567 - val_loss: 0.0304 - val_acc: 0.9699 - val_precision: 0.9711 - val_recall: 0.9711 - val_f1score: 0.9711\n",
            "Epoch 938/1000\n",
            "3410/3410 [==============================] - 0s 19us/sample - loss: 0.0434 - acc: 0.9545 - precision: 0.9517 - recall: 0.9517 - f1score: 0.9517 - val_loss: 0.0333 - val_acc: 0.9658 - val_precision: 0.9641 - val_recall: 0.9641 - val_f1score: 0.9641\n",
            "Epoch 939/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0431 - acc: 0.9537 - precision: 0.9561 - recall: 0.9561 - f1score: 0.9561 - val_loss: 0.0314 - val_acc: 0.9681 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 940/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0438 - acc: 0.9525 - precision: 0.9547 - recall: 0.9550 - f1score: 0.9549 - val_loss: 0.0325 - val_acc: 0.9658 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 941/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0434 - acc: 0.9528 - precision: 0.9553 - recall: 0.9556 - f1score: 0.9554 - val_loss: 0.0313 - val_acc: 0.9687 - val_precision: 0.9675 - val_recall: 0.9675 - val_f1score: 0.9675\n",
            "Epoch 942/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0436 - acc: 0.9522 - precision: 0.9550 - recall: 0.9547 - f1score: 0.9549 - val_loss: 0.0331 - val_acc: 0.9646 - val_precision: 0.9654 - val_recall: 0.9654 - val_f1score: 0.9654\n",
            "Epoch 943/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0435 - acc: 0.9519 - precision: 0.9544 - recall: 0.9544 - f1score: 0.9544 - val_loss: 0.0336 - val_acc: 0.9646 - val_precision: 0.9624 - val_recall: 0.9624 - val_f1score: 0.9624\n",
            "Epoch 944/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0437 - acc: 0.9531 - precision: 0.9556 - recall: 0.9556 - f1score: 0.9556 - val_loss: 0.0317 - val_acc: 0.9664 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 945/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0430 - acc: 0.9537 - precision: 0.9558 - recall: 0.9561 - f1score: 0.9560 - val_loss: 0.0320 - val_acc: 0.9658 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 946/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0428 - acc: 0.9540 - precision: 0.9564 - recall: 0.9564 - f1score: 0.9564 - val_loss: 0.0315 - val_acc: 0.9670 - val_precision: 0.9677 - val_recall: 0.9677 - val_f1score: 0.9677\n",
            "Epoch 947/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0429 - acc: 0.9540 - precision: 0.9561 - recall: 0.9561 - f1score: 0.9561 - val_loss: 0.0326 - val_acc: 0.9658 - val_precision: 0.9653 - val_recall: 0.9653 - val_f1score: 0.9653\n",
            "Epoch 948/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0426 - acc: 0.9545 - precision: 0.9569 - recall: 0.9567 - f1score: 0.9568 - val_loss: 0.0328 - val_acc: 0.9658 - val_precision: 0.9647 - val_recall: 0.9647 - val_f1score: 0.9647\n",
            "Epoch 949/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0428 - acc: 0.9545 - precision: 0.9517 - recall: 0.9517 - f1score: 0.9517 - val_loss: 0.0342 - val_acc: 0.9646 - val_precision: 0.9642 - val_recall: 0.9642 - val_f1score: 0.9642\n",
            "Epoch 950/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0436 - acc: 0.9534 - precision: 0.9506 - recall: 0.9506 - f1score: 0.9506 - val_loss: 0.0328 - val_acc: 0.9664 - val_precision: 0.9677 - val_recall: 0.9677 - val_f1score: 0.9677\n",
            "Epoch 951/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0428 - acc: 0.9537 - precision: 0.9561 - recall: 0.9561 - f1score: 0.9561 - val_loss: 0.0326 - val_acc: 0.9664 - val_precision: 0.9671 - val_recall: 0.9671 - val_f1score: 0.9671\n",
            "Epoch 952/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0431 - acc: 0.9537 - precision: 0.9561 - recall: 0.9558 - f1score: 0.9560 - val_loss: 0.0328 - val_acc: 0.9652 - val_precision: 0.9642 - val_recall: 0.9642 - val_f1score: 0.9642\n",
            "Epoch 953/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0430 - acc: 0.9540 - precision: 0.9564 - recall: 0.9567 - f1score: 0.9565 - val_loss: 0.0322 - val_acc: 0.9658 - val_precision: 0.9653 - val_recall: 0.9653 - val_f1score: 0.9653\n",
            "Epoch 954/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0426 - acc: 0.9545 - precision: 0.9517 - recall: 0.9517 - f1score: 0.9517 - val_loss: 0.0313 - val_acc: 0.9681 - val_precision: 0.9694 - val_recall: 0.9694 - val_f1score: 0.9694\n",
            "Epoch 955/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0440 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0330 - val_acc: 0.9658 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 956/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0434 - acc: 0.9537 - precision: 0.9508 - recall: 0.9511 - f1score: 0.9510 - val_loss: 0.0334 - val_acc: 0.9652 - val_precision: 0.9642 - val_recall: 0.9642 - val_f1score: 0.9642\n",
            "Epoch 957/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0422 - acc: 0.9540 - precision: 0.9511 - recall: 0.9508 - f1score: 0.9510 - val_loss: 0.0339 - val_acc: 0.9646 - val_precision: 0.9642 - val_recall: 0.9642 - val_f1score: 0.9642\n",
            "Epoch 958/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0423 - acc: 0.9548 - precision: 0.9572 - recall: 0.9572 - f1score: 0.9572 - val_loss: 0.0330 - val_acc: 0.9664 - val_precision: 0.9653 - val_recall: 0.9653 - val_f1score: 0.9653\n",
            "Epoch 959/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0430 - acc: 0.9537 - precision: 0.9561 - recall: 0.9561 - f1score: 0.9561 - val_loss: 0.0334 - val_acc: 0.9646 - val_precision: 0.9648 - val_recall: 0.9648 - val_f1score: 0.9648\n",
            "Epoch 960/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0438 - acc: 0.9522 - precision: 0.9550 - recall: 0.9547 - f1score: 0.9549 - val_loss: 0.0334 - val_acc: 0.9646 - val_precision: 0.9654 - val_recall: 0.9654 - val_f1score: 0.9654\n",
            "Epoch 961/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0422 - acc: 0.9554 - precision: 0.9578 - recall: 0.9578 - f1score: 0.9578 - val_loss: 0.0329 - val_acc: 0.9664 - val_precision: 0.9659 - val_recall: 0.9659 - val_f1score: 0.9659\n",
            "Epoch 962/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0429 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0337 - val_acc: 0.9640 - val_precision: 0.9630 - val_recall: 0.9630 - val_f1score: 0.9630\n",
            "Epoch 963/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0423 - acc: 0.9548 - precision: 0.9572 - recall: 0.9572 - f1score: 0.9572 - val_loss: 0.0328 - val_acc: 0.9658 - val_precision: 0.9647 - val_recall: 0.9647 - val_f1score: 0.9647\n",
            "Epoch 964/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0427 - acc: 0.9548 - precision: 0.9467 - recall: 0.9467 - f1score: 0.9467 - val_loss: 0.0351 - val_acc: 0.9634 - val_precision: 0.9613 - val_recall: 0.9613 - val_f1score: 0.9613\n",
            "Epoch 965/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0431 - acc: 0.9537 - precision: 0.9561 - recall: 0.9561 - f1score: 0.9561 - val_loss: 0.0332 - val_acc: 0.9658 - val_precision: 0.9647 - val_recall: 0.9647 - val_f1score: 0.9647\n",
            "Epoch 966/1000\n",
            "3410/3410 [==============================] - 0s 18us/sample - loss: 0.0438 - acc: 0.9531 - precision: 0.9450 - recall: 0.9450 - f1score: 0.9450 - val_loss: 0.0346 - val_acc: 0.9652 - val_precision: 0.9660 - val_recall: 0.9660 - val_f1score: 0.9660\n",
            "Epoch 967/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0428 - acc: 0.9537 - precision: 0.9456 - recall: 0.9456 - f1score: 0.9456 - val_loss: 0.0335 - val_acc: 0.9652 - val_precision: 0.9666 - val_recall: 0.9666 - val_f1score: 0.9666\n",
            "Epoch 968/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0432 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0332 - val_acc: 0.9652 - val_precision: 0.9660 - val_recall: 0.9660 - val_f1score: 0.9660\n",
            "Epoch 969/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0433 - acc: 0.9537 - precision: 0.9561 - recall: 0.9561 - f1score: 0.9561 - val_loss: 0.0327 - val_acc: 0.9658 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 970/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0435 - acc: 0.9537 - precision: 0.9559 - recall: 0.9561 - f1score: 0.9560 - val_loss: 0.0325 - val_acc: 0.9670 - val_precision: 0.9664 - val_recall: 0.9664 - val_f1score: 0.9664\n",
            "Epoch 971/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0440 - acc: 0.9522 - precision: 0.9494 - recall: 0.9494 - f1score: 0.9494 - val_loss: 0.0332 - val_acc: 0.9652 - val_precision: 0.9666 - val_recall: 0.9666 - val_f1score: 0.9666\n",
            "Epoch 972/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0425 - acc: 0.9543 - precision: 0.9514 - recall: 0.9514 - f1score: 0.9514 - val_loss: 0.0343 - val_acc: 0.9640 - val_precision: 0.9655 - val_recall: 0.9655 - val_f1score: 0.9655\n",
            "Epoch 973/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0424 - acc: 0.9554 - precision: 0.9578 - recall: 0.9578 - f1score: 0.9578 - val_loss: 0.0330 - val_acc: 0.9652 - val_precision: 0.9642 - val_recall: 0.9642 - val_f1score: 0.9642\n",
            "Epoch 974/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0424 - acc: 0.9545 - precision: 0.9570 - recall: 0.9572 - f1score: 0.9571 - val_loss: 0.0327 - val_acc: 0.9646 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1score: 0.9661\n",
            "Epoch 975/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0427 - acc: 0.9545 - precision: 0.9517 - recall: 0.9517 - f1score: 0.9517 - val_loss: 0.0332 - val_acc: 0.9652 - val_precision: 0.9648 - val_recall: 0.9648 - val_f1score: 0.9648\n",
            "Epoch 976/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0434 - acc: 0.9534 - precision: 0.9453 - recall: 0.9453 - f1score: 0.9453 - val_loss: 0.0330 - val_acc: 0.9658 - val_precision: 0.9653 - val_recall: 0.9653 - val_f1score: 0.9653\n",
            "Epoch 977/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0423 - acc: 0.9554 - precision: 0.9578 - recall: 0.9578 - f1score: 0.9578 - val_loss: 0.0331 - val_acc: 0.9652 - val_precision: 0.9654 - val_recall: 0.9654 - val_f1score: 0.9654\n",
            "Epoch 978/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0438 - acc: 0.9531 - precision: 0.9558 - recall: 0.9556 - f1score: 0.9557 - val_loss: 0.0323 - val_acc: 0.9664 - val_precision: 0.9640 - val_recall: 0.9640 - val_f1score: 0.9640\n",
            "Epoch 979/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0431 - acc: 0.9540 - precision: 0.9564 - recall: 0.9561 - f1score: 0.9562 - val_loss: 0.0329 - val_acc: 0.9652 - val_precision: 0.9666 - val_recall: 0.9666 - val_f1score: 0.9666\n",
            "Epoch 980/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0425 - acc: 0.9540 - precision: 0.9511 - recall: 0.9511 - f1score: 0.9511 - val_loss: 0.0335 - val_acc: 0.9640 - val_precision: 0.9643 - val_recall: 0.9643 - val_f1score: 0.9643\n",
            "Epoch 981/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0429 - acc: 0.9543 - precision: 0.9567 - recall: 0.9569 - f1score: 0.9568 - val_loss: 0.0324 - val_acc: 0.9658 - val_precision: 0.9659 - val_recall: 0.9659 - val_f1score: 0.9659\n",
            "Epoch 982/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0424 - acc: 0.9548 - precision: 0.9572 - recall: 0.9572 - f1score: 0.9572 - val_loss: 0.0324 - val_acc: 0.9658 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 983/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0423 - acc: 0.9548 - precision: 0.9572 - recall: 0.9572 - f1score: 0.9572 - val_loss: 0.0324 - val_acc: 0.9658 - val_precision: 0.9647 - val_recall: 0.9647 - val_f1score: 0.9647\n",
            "Epoch 984/1000\n",
            "3410/3410 [==============================] - 0s 17us/sample - loss: 0.0426 - acc: 0.9548 - precision: 0.9570 - recall: 0.9572 - f1score: 0.9571 - val_loss: 0.0330 - val_acc: 0.9646 - val_precision: 0.9654 - val_recall: 0.9654 - val_f1score: 0.9654\n",
            "Epoch 985/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0429 - acc: 0.9548 - precision: 0.9467 - recall: 0.9467 - f1score: 0.9467 - val_loss: 0.0331 - val_acc: 0.9646 - val_precision: 0.9630 - val_recall: 0.9630 - val_f1score: 0.9630\n",
            "Epoch 986/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0431 - acc: 0.9540 - precision: 0.9511 - recall: 0.9511 - f1score: 0.9511 - val_loss: 0.0328 - val_acc: 0.9652 - val_precision: 0.9660 - val_recall: 0.9660 - val_f1score: 0.9660\n",
            "Epoch 987/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0432 - acc: 0.9537 - precision: 0.9561 - recall: 0.9561 - f1score: 0.9561 - val_loss: 0.0330 - val_acc: 0.9646 - val_precision: 0.9654 - val_recall: 0.9654 - val_f1score: 0.9654\n",
            "Epoch 988/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0424 - acc: 0.9551 - precision: 0.9575 - recall: 0.9575 - f1score: 0.9575 - val_loss: 0.0334 - val_acc: 0.9652 - val_precision: 0.9654 - val_recall: 0.9654 - val_f1score: 0.9654\n",
            "Epoch 989/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0417 - acc: 0.9557 - precision: 0.9581 - recall: 0.9581 - f1score: 0.9581 - val_loss: 0.0322 - val_acc: 0.9658 - val_precision: 0.9665 - val_recall: 0.9665 - val_f1score: 0.9665\n",
            "Epoch 990/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0426 - acc: 0.9543 - precision: 0.9567 - recall: 0.9567 - f1score: 0.9567 - val_loss: 0.0340 - val_acc: 0.9640 - val_precision: 0.9630 - val_recall: 0.9630 - val_f1score: 0.9630\n",
            "Epoch 991/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0424 - acc: 0.9545 - precision: 0.9569 - recall: 0.9569 - f1score: 0.9569 - val_loss: 0.0323 - val_acc: 0.9658 - val_precision: 0.9659 - val_recall: 0.9659 - val_f1score: 0.9659\n",
            "Epoch 992/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0425 - acc: 0.9543 - precision: 0.9514 - recall: 0.9514 - f1score: 0.9514 - val_loss: 0.0348 - val_acc: 0.9628 - val_precision: 0.9625 - val_recall: 0.9625 - val_f1score: 0.9625\n",
            "Epoch 993/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0433 - acc: 0.9537 - precision: 0.9561 - recall: 0.9561 - f1score: 0.9561 - val_loss: 0.0330 - val_acc: 0.9646 - val_precision: 0.9648 - val_recall: 0.9648 - val_f1score: 0.9648\n",
            "Epoch 994/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0415 - acc: 0.9566 - precision: 0.9483 - recall: 0.9483 - f1score: 0.9483 - val_loss: 0.0346 - val_acc: 0.9628 - val_precision: 0.9632 - val_recall: 0.9632 - val_f1score: 0.9632\n",
            "Epoch 995/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0433 - acc: 0.9528 - precision: 0.9553 - recall: 0.9553 - f1score: 0.9553 - val_loss: 0.0335 - val_acc: 0.9646 - val_precision: 0.9648 - val_recall: 0.9648 - val_f1score: 0.9648\n",
            "Epoch 996/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0424 - acc: 0.9554 - precision: 0.9525 - recall: 0.9525 - f1score: 0.9525 - val_loss: 0.0338 - val_acc: 0.9640 - val_precision: 0.9637 - val_recall: 0.9637 - val_f1score: 0.9637\n",
            "Epoch 997/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0428 - acc: 0.9540 - precision: 0.9564 - recall: 0.9564 - f1score: 0.9564 - val_loss: 0.0314 - val_acc: 0.9676 - val_precision: 0.9670 - val_recall: 0.9670 - val_f1score: 0.9670\n",
            "Epoch 998/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0428 - acc: 0.9537 - precision: 0.9456 - recall: 0.9456 - f1score: 0.9456 - val_loss: 0.0339 - val_acc: 0.9646 - val_precision: 0.9661 - val_recall: 0.9661 - val_f1score: 0.9661\n",
            "Epoch 999/1000\n",
            "3410/3410 [==============================] - 0s 16us/sample - loss: 0.0426 - acc: 0.9543 - precision: 0.9567 - recall: 0.9567 - f1score: 0.9567 - val_loss: 0.0324 - val_acc: 0.9664 - val_precision: 0.9683 - val_recall: 0.9683 - val_f1score: 0.9683\n",
            "Epoch 1000/1000\n",
            "3410/3410 [==============================] - 0s 15us/sample - loss: 0.0430 - acc: 0.9534 - precision: 0.9558 - recall: 0.9558 - f1score: 0.9558 - val_loss: 0.0337 - val_acc: 0.9640 - val_precision: 0.9649 - val_recall: 0.9649 - val_f1score: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMNfQA7MCjLx",
        "outputId": "b003dc9a-467a-4791-8f0d-0754aed0c555"
      },
      "source": [
        "## summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "## summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VdSL6OhpCjLx",
        "outputId": "c928dedc-a213-4365-aafc-3a0c7c001224"
      },
      "source": [
        "_loss, _acc, _precision, _recall, _f1score = model.evaluate(now_x, now_y, batch_size=batch_size, verbose=0)\n",
        "print('loss: {:.4f}, accuracy: {:.4f}, precision: {:.4f}, recall: {:.4f}, f1score: {:.4f}'.format(_loss, _acc, _precision, _recall, _f1score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
            "loss: 0.0326, accuracy: 0.9652, precision: 0.9660, recall: 0.9660, f1score: 0.9660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kzz9AQa-CjLx",
        "outputId": "e50e5581-dbe8-4b9e-cae5-636361e6f6b6"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_pred_keras = model.predict(now_x)\n",
        "print(y_pred_keras)\n",
        "#ROC (Receiver Operating Characteristic)  AUC (Area Under Curve, 곡선 아래 면적)\n",
        "score = roc_auc_score(now_y, y_pred_keras) \n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
            "[[9.7384399e-01 2.6196957e-02]\n",
            " [9.7209728e-01 2.7946025e-02]\n",
            " [8.9160109e-01 1.0845992e-01]\n",
            " ...\n",
            " [9.7551179e-01 2.4526834e-02]\n",
            " [6.0603023e-04 9.9939424e-01]\n",
            " [9.5720410e-01 4.2837083e-02]]\n",
            "0.5047196227249282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6V_JmjRCjLy",
        "outputId": "144b87cb-cf91-4102-f053-b5bd23354e6b"
      },
      "source": [
        "fprs, tprs, thresholds = metrics.roc_curve(now_y.idxmax(axis=1), y_pred_keras.argmax(axis=1))\n",
        "plt.figure()\n",
        "plt.plot([0,0],[1,1], label='STR',  color='green', linestyle='--')\n",
        "plt.plot(fprs, tprs, label='ROC', color='red')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1doSRJyHCjLy",
        "outputId": "e03b5486-dc0a-452d-eb23-cfeb2ace4287"
      },
      "source": [
        "#For fundsimulation using vali data \n",
        "new_funsim = []\n",
        "new_code = []\n",
        "new_date = []\n",
        "new_zero = []\n",
        "#vali_code_arr.append(code)\n",
        "#vali_date_arr.append(date)\n",
        "pred_funsim = model.predict(vali_x)\n",
        "print(pred_funsim.argmax(axis=1))\n",
        "for i in range(len(pred_funsim)):\n",
        "    if pred_funsim[i][0] < pred_funsim[i][1]:\n",
        "        new_funsim.append(pred_funsim[i][1])\n",
        "        new_date.append(vali_date_arr[i])\n",
        "        new_code.append(vali_code_arr[i])\n",
        "        new_zero.append(0.0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY0_FMGNCjLz"
      },
      "source": [
        "funsim_code = pd.DataFrame(new_code, columns=['code'])\n",
        "funsim_date = pd.DataFrame(new_date, columns=['date'])\n",
        "funsim_rate = pd.DataFrame(new_funsim, columns=['rate'])\n",
        "funsim_zero = pd.DataFrame(new_zero, columns=['zero'])\n",
        "funsim_code = funsim_code.astype(str)\n",
        "funsim_date = funsim_date.astype(int)\n",
        "pred_funsimDataframe = pd.concat([funsim_code, funsim_date, funsim_rate, funsim_zero], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBdtKr2fCjLz"
      },
      "source": [
        "pred_funsimDataframe['code'] = pred_funsimDataframe['code'].str.zfill(width=8)\n",
        "pred_funsimDataframe['code'] = pred_funsimDataframe['code'].str.replace(pat='.0', repl='', regex=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pai9EMfYCjLz"
      },
      "source": [
        "pred_funsimDataframe = pred_funsimDataframe.sort_values(by='date')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uURHzPl2CjLz"
      },
      "source": [
        "pred_funsimDataframe.to_csv('hivol-예측치_date.txt', sep = ',', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9naOg6hCjL0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gopQejUtCjL0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}